from typing import Any, Dict, List, Optional
import random
import time
import requests
import json
import os
from openai import OpenAI

from .base import BaseLLMService
from .schemas import LLMGenerationRequest, AgentInvokeRequest, AgentResponse, Agent
from ..tools import ToolRegistry, ToolRequest, ToolResponse, BaseTool, ToolRegistrationRequest
from ..config import settings


class PrismLLMService(BaseLLMService):
    """
    PRISM-Core ì „ìš© LLM ì„œë¹„ìŠ¤ (OpenAI-Compatible vLLM ì„œë²„ í´ë¼ì´ì–¸íŠ¸)
    
    - chat completions ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€/íˆ´ ê¸°ë°˜ ëŒ€í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•  ê²½ìš° ê°„ë‹¨í•œ íˆ´ ì½œ ë£¨í”„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ì—ì´ì „íŠ¸/ë„êµ¬ ë“±ë¡ì€ ê¸°ì¡´ PRISM-Core APIë¥¼ í†µí•´ ì§€ì†
    """
    
    def __init__(self, 
                 model_name: Optional[str] = None, 
                 simulate_delay: bool = False, 
                 tool_registry: Optional[ToolRegistry] = None,
                 llm_service_url: str = "http://localhost:8000",
                 agent_name: str = "orchestration_agent",
                 openai_base_url: Optional[str] = None,
                 api_key: Optional[str] = None):
        """
        PrismLLMService ì´ˆê¸°í™”
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ VLLM_MODEL í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” settings.model_name ì‚¬ìš©)
            simulate_delay: í…ŒìŠ¤íŠ¸ìš© ì‘ë‹µ ì§€ì—° ì—¬ë¶€
            tool_registry: ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (invoke ê¸°ëŠ¥ìš©)
            llm_service_url: PRISM-Core API URL (ì—ì´ì „íŠ¸/ë„êµ¬ ë“±ë¡ì— ì‚¬ìš©)
            agent_name: ê¸°ë³¸ ì—ì´ì „íŠ¸ ì´ë¦„
            openai_base_url: vLLM OpenAI-compatible ì„œë²„ base URL (ì˜ˆ: http://host:8001/v1)
            api_key: OpenAI í˜¸í™˜ API í‚¤ (ê¸°ë³¸ì€ EMPTY)
        """
        # ëª¨ë¸ëª… í•´ì„: ìš°ì„ ìˆœìœ„ model_name arg > env VLLM_MODEL > settings.model_name
        resolved_model = model_name or os.getenv("VLLM_MODEL") or settings.model_name
        self.model_name = resolved_model
        self.simulate_delay = simulate_delay
        self.tool_registry = tool_registry or ToolRegistry()
        self.llm_service_url = llm_service_url.rstrip('/')
        self.agent_name = agent_name
        self.session = requests.Session()
        self.session.timeout = 30

        # OpenAI-compatible vLLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        base_url = (openai_base_url or settings.vllm_openai_base_url).rstrip('/')
        if not base_url.endswith("/v1"):
            base_url = f"{base_url}/v1"
        self.client = OpenAI(base_url=base_url, api_key=api_key or settings.openai_api_key)
        
        # ì œì¡°ì—… ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ì‘ë‹µ í…œí”Œë¦¿ (í´ë°±ìš©)
        self.response_templates = {
            "pressure": [
                "ì••ë ¥ ì´ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ë‹¤ìŒ ì¡°ì¹˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:\n1. ì••ë ¥ ì„¼ì„œ ì ê²€\n2. ë°¸ë¸Œ ìƒíƒœ í™•ì¸\n3. ë°°ê´€ ëˆ„ì¶œ ê²€ì‚¬\n4. ì•ˆì „ í”„ë¡œí† ì½œ ì‹¤í–‰",
                "ì••ë ¥ ìƒìŠ¹ ì›ì¸ì„ ë¶„ì„í•œ ê²°ê³¼, ë°¸ë¸Œ ì˜¤ìž‘ë™ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. ì •ë¹„íŒ€ì— ì¦‰ì‹œ ì—°ë½í•˜ì—¬ V-001 ë°¸ë¸Œë¥¼ ì ê²€í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤.",
                "ì••ë ¥ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•œ ê²°ê³¼, ì •ìƒ ë²”ìœ„(1.0-3.5 bar)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê¸´ê¸‰ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
            ],
            "temperature": [
                "ì˜¨ë„ ì„¼ì„œ ì´ìƒì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì ê²€ ì ˆì°¨ë¥¼ ë”°ë¥´ì„¸ìš”:\n1. ì„¼ì„œ ì¼€ì´ë¸” ì—°ê²° ìƒíƒœ í™•ì¸\n2. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ì ê²€\n3. ì£¼ë³€ í™˜ê²½ ì˜¨ë„ ì¸¡ì •",
                "T-002 ì„¼ì„œì˜ íŒ¨í„´ ë¶„ì„ ê²°ê³¼, ì£¼ê¸°ì ì¸ ìŠ¤íŒŒì´í¬ê°€ ë°œê²¬ë©ë‹ˆë‹¤. ì „ê¸°ì  ê°„ì„­ì´ë‚˜ ê¸°ê³„ì  ì§„ë™ì„ í™•ì¸í•´ë³´ì„¸ìš”.",
                "ì˜¨ë„ ì„¼ì„œ êµì²´ë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤. í˜„ìž¬ ì„¼ì„œì˜ ì •í™•ë„ê°€ í—ˆìš© ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤."
            ],
            "general": [
                "ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ìƒíƒœ ì ê²€ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ íŒŒë¼ë¯¸í„°ê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìžˆìœ¼ë‚˜, ì •ê¸° ìœ ì§€ë³´ìˆ˜ê°€ í•„ìš”í•œ ë¶€ë¶„ì´ ìžˆìŠµë‹ˆë‹¤.",
                "ì•¼ê°„ êµëŒ€ ì¤€ë¹„ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ ì ê²€ ê²°ê³¼ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤. ëª¨ë“  ì•ˆì „ ì‹œìŠ¤í…œì´ ì •ìƒ ìž‘ë™ ì¤‘ì´ë©°, íŠ¹ë³„í•œ ì£¼ì˜ì‚¬í•­ì€ ì—†ìŠµë‹ˆë‹¤.",
                "ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ë‹¤ìŒ ì ê²€ ì¼ì •ì— ë§žì¶° ì˜ˆë°© ì •ë¹„ë¥¼ ì‹¤ì‹œí•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤."
            ]
        }
    
    def generate(self, request: LLMGenerationRequest) -> str:
        """
        OpenAI-Compatible vLLM ì„œë²„ì˜ chat completions ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ìƒì„±
        - messages ë˜ëŠ” extra_body["messages"]ê°€ ë°˜ë“œì‹œ ì¡´ìž¬í•´ì•¼ í•©ë‹ˆë‹¤
        """
        try:
            messages = request.messages or ((request.extra_body or {}).get("messages") if request.extra_body else None)
            if not messages:
                raise ValueError("PrismLLMService.generate: 'messages' is required for chat completions.")

            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=request.temperature,
                max_tokens=request.max_tokens,
                stop=request.stop,
                extra_body=request.extra_body or None,
            )
            return resp.choices[0].message.content or ""
        except Exception as e:
            print(f"âš ï¸  OpenAI-compatible chat í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._generate_fallback_response(request)
    
    def _generate_fallback_response(self, request: LLMGenerationRequest) -> str:
        """
        ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ ìƒì„±
        """
        if self.simulate_delay:
            time.sleep(random.uniform(0.5, 2.0))
        
        prompt = (request.prompt or "").lower()
        
        # í”„ë¡¬í”„íŠ¸ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µ ì„ íƒ
        if "ì••ë ¥" in prompt or "pressure" in prompt:
            responses = self.response_templates["pressure"]
        elif "ì˜¨ë„" in prompt or "temperature" in prompt:
            responses = self.response_templates["temperature"]
        else:
            responses = self.response_templates["general"]
        
        base_response = random.choice(responses)
        
        enhanced_response = f"""## PRISM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‘ë‹µ (í´ë°± ëª¨ë“œ)

{base_response}

### ê¶Œìž¥ ì¡°ì¹˜ì‚¬í•­:
- ì¦‰ì‹œ í•´ë‹¹ ì‹œìŠ¤í…œ ë‹´ë‹¹ìžì—ê²Œ ë³´ê³ 
- ì•ˆì „ í”„ë¡œí† ì½œ ì¤€ìˆ˜
- ì¡°ì¹˜ ê²°ê³¼ë¥¼ ì‹œìŠ¤í…œì— ê¸°ë¡

### ì¶”ê°€ ì •ë³´:
- ë¶„ì„ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}
- ëª¨ë¸: {self.model_name} (í´ë°± ëª¨ë“œ)
- ì‹ ë¢°ë„: {random.randint(85, 98)}%

---
*ì´ ì‘ë‹µì€ PRISM-Core ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í´ë°± ëª¨ë“œì— ì˜í•´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*"""

        return enhanced_response
    
    def _map_tools_to_openai(self) -> List[Dict[str, Any]]:
        """ToolRegistryì˜ ë„êµ¬ë“¤ì„ OpenAI tools í¬ë§·ìœ¼ë¡œ ë§¤í•‘"""
        tools: List[Dict[str, Any]] = []
        for tool in self.tool_registry.list_tools():
            tools.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": getattr(tool, "description", ""),
                    "parameters": getattr(tool, "parameters_schema", {}),
                },
            })
        return tools
    
    def register_agent(self, agent: Agent) -> bool:
        """
        PRISM-Core ì„œë¹„ìŠ¤ì— ì—ì´ì „íŠ¸ ë“±ë¡
        """
        try:
            # Pre-check: if agent already exists on server, skip remote registration
            try:
                existing = self.get_agents() or []
                if any((a.get("name") == agent.name) for a in existing if isinstance(a, dict)):
                    print(f"â„¹ï¸  ì—ì´ì „íŠ¸ '{agent.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    return True
            except Exception:
                pass

            url = f"{self.llm_service_url}/api/agents"
            payload = {
                "name": agent.name,
                "description": agent.description,
                "role_prompt": agent.role_prompt,
                "tools": agent.tools
            }
            response = self.session.post(url, json=payload)
            if response.status_code == 400:
                # Treat duplicate as success
                try:
                    detail = response.json()
                except Exception:
                    detail = {"detail": response.text}
                if isinstance(detail, dict) and ("already" in str(detail.get("detail", ""))):
                    print(f"â„¹ï¸  ì—ì´ì „íŠ¸ '{agent.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    return True
            response.raise_for_status()
            print(f"âœ… ì—ì´ì „íŠ¸ '{agent.name}' ë“±ë¡ ì„±ê³µ")
            return True
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ '{agent.name}' ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ë“±ë¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def register_tool(self, tool: BaseTool) -> bool:
        """
        PRISM-Core ì„œë¹„ìŠ¤ì— ë„êµ¬ ë“±ë¡
        """
        try:
            # Pre-check: if tool already exists on server, skip remote registration
            try:
                existing = self.get_tools() or []
                if any((t.get("name") == tool.name) for t in existing if isinstance(t, dict)):
                    print(f"â„¹ï¸  ë„êµ¬ '{tool.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    try:
                        self.tool_registry.register_tool(tool)
                    except Exception:
                        pass
                    return True
            except Exception:
                # If listing fails, proceed to try registering
                pass

            url = f"{self.llm_service_url}/api/tools"
            payload = {
                "name": tool.name,
                "description": tool.description,
                "parameters_schema": tool.parameters_schema,
                "tool_type": "custom"
            }
            response = self.session.post(url, json=payload)
            # Treat duplicate registration as success
            if response.status_code == 400:
                try:
                    detail = response.json()
                except Exception:
                    detail = {"detail": response.text}
                if isinstance(detail, dict) and "already registered" in str(detail.get("detail", "")):
                    print(f"â„¹ï¸  ë„êµ¬ '{tool.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    try:
                        self.tool_registry.register_tool(tool)
                    except Exception:
                        pass
                    return True
            response.raise_for_status()
            print(f"âœ… ë„êµ¬ '{tool.name}' ë“±ë¡ ì„±ê³µ")
            # ë¡œì»¬ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ë„ ë“±ë¡
            self.tool_registry.register_tool(tool)
            return True
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ '{tool.name}' ë“±ë¡ ì‹¤íŒ¨: {e}")
            try:
                self.tool_registry.register_tool(tool)
                print(f"  ðŸ’¡ ë¡œì»¬ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ëŠ” ë“±ë¡ë¨")
            except:
                pass
            return False
        except Exception as e:
            print(f"âŒ ë„êµ¬ ë“±ë¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def assign_tools_to_agent(self, agent_name: str, tool_names: List[str]) -> bool:
        """
        ì—ì´ì „íŠ¸ì— ë„êµ¬ í• ë‹¹
        """
        try:
            url = f"{self.llm_service_url}/api/agents/{agent_name}/tools"
            payload = {"agent_name": agent_name, "tool_names": tool_names}
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            print(f"âœ… ì—ì´ì „íŠ¸ '{agent_name}'ì— ë„êµ¬ í• ë‹¹ ì„±ê³µ: {', '.join(tool_names)}")
            return True
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ í• ë‹¹ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"âŒ ë„êµ¬ í• ë‹¹ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def get_agents(self) -> List[Dict[str, Any]]:
        try:
            url = f"{self.llm_service_url}/api/agents"
            response = self.session.get(url)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return []
    
    def get_tools(self) -> List[Dict[str, Any]]:
        try:
            url = f"{self.llm_service_url}/api/tools"
            response = self.session.get(url)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        except Exception as e:
            print(f"âŒ ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return []
    
    def setup_complete_system(self, agents: List[Agent], tools: List[BaseTool]) -> bool:
        print(f"ðŸš€ ì™„ì „í•œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì„¤ì • ì‹œìž‘")
        print(f"  ðŸ“ ì—ì´ì „íŠ¸: {len(agents)}ê°œ")
        print(f"  ðŸ› ï¸  ë„êµ¬: {len(tools)}ê°œ")
        success_count = 0
        total_operations = len(tools) + len(agents)
        print(f"\nðŸ”§ 1ë‹¨ê³„: ë„êµ¬ ë“±ë¡")
        for tool in tools:
            if self.register_tool(tool):
                success_count += 1
        print(f"\nðŸ¤– 2ë‹¨ê³„: ì—ì´ì „íŠ¸ ë“±ë¡")
        for agent in agents:
            if self.register_agent(agent):
                success_count += 1
                if agent.tools:
                    self.assign_tools_to_agent(agent.name, agent.tools)
        success_rate = (success_count / total_operations) * 100 if total_operations > 0 else 0
        print(f"\nðŸ“Š ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ:")
        print(f"  âœ… ì„±ê³µ: {success_count}/{total_operations} ({success_rate:.1f}%)")
        return success_count == total_operations
    
    async def invoke_agent(self, agent, request: AgentInvokeRequest) -> AgentResponse:
        """
        OpenAI-Compatible chat completionsë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ í˜¸ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        - toolsë¥¼ OpenAI í¬ë§·ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ ëª¨ë¸ì´ í•¨ìˆ˜ í˜¸ì¶œì„ ì„ íƒí•˜ë„ë¡ ìœ ë„
        - ëª¨ë¸ì´ tool_callsë¥¼ ìƒì„±í•˜ë©´ ë¡œì»¬ ë„êµ¬ë¥¼ ì‹¤í–‰í•´ ê²°ê³¼ë¥¼ messagesì— ì¶”ê°€í•œ ë’¤ ìž¬í˜¸ì¶œ
        - ìµœì¢… contentë¥¼ ë°˜í™˜
        """
        if self.simulate_delay:
            time.sleep(random.uniform(0.3, 1.0))
        
        tools_used: List[str] = []
        tool_results: List[Dict[str, Any]] = []
        
        # ì´ˆê¸° ë©”ì‹œì§€ êµ¬ì„± (system + user)
        messages: List[Dict[str, Any]] = [
            {"role": "system", "content": agent.role_prompt},
            {"role": "user", "content": request.prompt},
        ]

        tools_spec = self._map_tools_to_openai() if (request.use_tools and agent.tools) else None
        max_tool_calls = getattr(request, "max_tool_calls", 3) or 3

        # Tool call ë£¨í”„
        for _ in range(max_tool_calls):
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                tools=tools_spec,
                temperature=request.temperature,
                max_tokens=request.max_tokens,
                stop=request.stop,
                extra_body=request.extra_body or None,
            )
            choice = resp.choices[0]
            msg = choice.message.model_dump()

            # tool calls ì²˜ë¦¬
            tool_calls = msg.get("tool_calls") or []
            if tool_calls:
                messages.append({
                    "role": "assistant",
                    "content": msg.get("content"),
                    "tool_calls": tool_calls,
                })
                for tc in tool_calls:
                    fn = tc.get("function", {})
                    fn_name = fn.get("name")
                    fn_args_json = fn.get("arguments", "{}")
                    try:
                        fn_args = json.loads(fn_args_json)
                    except Exception:
                        fn_args = {}
                    # ë¡œì»¬ ë„êµ¬ ì‹¤í–‰
                    tool = self.tool_registry.get_tool(fn_name)
                    if tool:
                        try:
                            tr = ToolRequest(tool_name=fn_name, parameters=fn_args)
                            tresp = await tool.execute(tr)
                            tools_used.append(fn_name)
                            tool_results.append({
                                "tool": fn_name,
                                "result": tresp.result,
                                "message": tresp.message,
                            })
                            messages.append({
                                "role": "tool",
                                "content": json.dumps(tresp.result or {}),
                                "tool_call_id": tc.get("id"),
                            })
                        except Exception as tool_err:
                            messages.append({
                                "role": "tool",
                                "content": json.dumps({"error": str(tool_err)}),
                                "tool_call_id": tc.get("id"),
                            })
                    else:
                        messages.append({
                            "role": "tool",
                            "content": json.dumps({"error": f"tool '{fn_name}' not found"}),
                            "tool_call_id": tc.get("id"),
                        })
                # ë‹¤ìŒ ë£¨í”„ì—ì„œ ë©”ì‹œì§€/íˆ´ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ìž¬í˜¸ì¶œ
                continue
            
            # ìµœì¢… ì‘ë‹µ
            final_content = msg.get("content") or ""
            return AgentResponse(
                text=final_content,
                tools_used=tools_used,
                tool_results=tool_results,
                metadata={
                    "agent_name": agent.name,
                    "model": self.model_name,
                    "tool_count": len(tools_used),
                }
            )

        # ìµœëŒ€ íˆ´ ì½œ ì´ˆê³¼ ì‹œ ë§ˆì§€ë§‰ ì‘ë‹µ ì‹œë„
        final_resp = self.client.chat.completions.create(
            model=self.model_name,
            messages=messages,
            tools=tools_spec,
            temperature=request.temperature,
            max_tokens=request.max_tokens,
            stop=request.stop,
            extra_body=request.extra_body or None,
        )
        final_text = final_resp.choices[0].message.content or ""
        return AgentResponse(
            text=final_text,
            tools_used=tools_used,
            tool_results=tool_results,
            metadata={
                "agent_name": agent.name,
                "model": self.model_name,
                "tool_count": len(tools_used),
            }
        )
    
    def _build_agent_prompt(self, agent, user_prompt: str, tool_results: List[Dict]) -> str:
        """(Deprecated) ë¬¸ìžì—´ í”„ë¡¬í”„íŠ¸ ë°©ì‹ ìœ ì§€ìš© - í˜„ìž¬ëŠ” chat ê¸°ë°˜ ì‚¬ìš©"""
        prompt_parts = [agent.role_prompt, f"\nì‚¬ìš©ìž ìš”ì²­: {user_prompt}"]
        if tool_results:
            prompt_parts.append("\n\në„êµ¬ ì‹¤í–‰ ê²°ê³¼:")
            for result in tool_results:
                prompt_parts.append(f"- {result['tool']}: {result['message']}")
                if result['result']:
                    prompt_parts.append(f"  ë°ì´í„°: {str(result['result'])[:200]}...")
        prompt_parts.append("\n\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìžì—ê²Œ ì¢…í•©ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.")
        return "\n".join(prompt_parts)
    
    def get_model_info(self) -> Dict[str, Any]:
        return {
            "name": self.model_name,
            "type": "prism-llm",
            "version": "1.0.0",
            "description": "PRISM-Core ì „ìš© ì œì¡°ì—… íŠ¹í™” LLM ì„œë¹„ìŠ¤",
            "capabilities": [
                "manufacturing_analysis",
                "safety_assessment", 
                "maintenance_planning",
                "korean_language"
            ]
        } 