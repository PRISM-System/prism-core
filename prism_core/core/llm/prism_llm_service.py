from logging import warning
from typing import Any, Dict, List, Optional
import random
import time
import requests
import json
import os
import socket
from openai import OpenAI

from .base import BaseLLMService
from .schemas import LLMGenerationRequest, AgentInvokeRequest, AgentResponse, Agent
from ..tools import ToolRegistry, ToolRequest, ToolResponse, BaseTool, ToolRegistrationRequest
from ..config import settings


class PrismLLMService(BaseLLMService):
    """
    PRISM-Core ì „ìš© LLM ì„œë¹„ìŠ¤ (OpenAI-Compatible vLLM ì„œë²„ í´ë¼ì´ì–¸íŠ¸)
    
    - chat completions ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€/íˆ´ ê¸°ë°˜ ëŒ€í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•  ê²½ìš° ê°„ë‹¨í•œ íˆ´ ì½œ ë£¨í”„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ì—ì´ì „íŠ¸/ë„êµ¬ ë“±ë¡ì€ ê¸°ì¡´ PRISM-Core APIë¥¼ í†µí•´ ì§€ì†
    """
    
    def __init__(self, 
                 model_name: Optional[str] = None, 
                 simulate_delay: bool = False, 
                 tool_registry: Optional[ToolRegistry] = None,
                 llm_service_url: str = "http://localhost:8000",
                 agent_name: str = "orchestration_agent",
                 openai_base_url: Optional[str] = None,
                 api_key: Optional[str] = None):
        """
        PrismLLMService ì´ˆê¸°í™”
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ VLLM_MODEL í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” settings.model_name ì‚¬ìš©)
            simulate_delay: í…ŒìŠ¤íŠ¸ìš© ì‘ë‹µ ì§€ì—° ì—¬ë¶€
            tool_registry: ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (invoke ê¸°ëŠ¥ìš©)
            llm_service_url: PRISM-Core API URL (ì—ì´ì „íŠ¸/ë„êµ¬ ë“±ë¡ì— ì‚¬ìš©)
            agent_name: ê¸°ë³¸ ì—ì´ì „íŠ¸ ì´ë¦„
            openai_base_url: vLLM OpenAI-compatible ì„œë²„ base URL (ì˜ˆ: http://host:8001/v1)
            api_key: OpenAI í˜¸í™˜ API í‚¤ (ê¸°ë³¸ì€ EMPTY)
        """
        import sys
        print("ðŸ”§ [STEP 6-1] Starting PrismLLMService initialization...", file=sys.stderr, flush=True)
        
        # ëª¨ë¸ëª… í•´ì„: ìš°ì„ ìˆœìœ„ model_name arg > env VLLM_MODEL > settings.model_name
        resolved_model = model_name or os.getenv("VLLM_MODEL") or settings.model_name
        self.model_name = resolved_model
        print(f"ðŸ”§ [STEP 6-2] Model name resolved: {self.model_name}", file=sys.stderr, flush=True)
        
        self.simulate_delay = simulate_delay
        print("ðŸ”§ [STEP 6-3] Creating tool registry...", file=sys.stderr, flush=True)
        self.tool_registry = tool_registry or ToolRegistry()
        print("ðŸ”§ [STEP 6-4] Tool registry created", file=sys.stderr, flush=True)
        
        self.llm_service_url = llm_service_url.rstrip('/')
        self.agent_name = agent_name
        print("ðŸ”§ [STEP 6-5] Creating requests session...", file=sys.stderr, flush=True)
        self.session = requests.Session()
        print("ðŸ”§ [STEP 6-6] Requests session created", file=sys.stderr, flush=True)

        # OpenAI-compatible vLLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        print("ðŸ”§ [STEP 6-7] Setting up OpenAI client...", file=sys.stderr, flush=True)
        base_url = (openai_base_url or settings.VLLM_OPENAI_BASE_URL).rstrip('/')
        if not base_url.endswith("/v1"):
            base_url = f"{base_url}/v1"
        print(f"ðŸ”§ [STEP 6-8] Base URL: {base_url}", file=sys.stderr, flush=True)
        print(f"ðŸ”§ [STEP 6-9] API Key: {'***' if (api_key or settings.OPENAI_API_KEY) else 'None'}", file=sys.stderr, flush=True)
        
        self.client = OpenAI(base_url=base_url, api_key=api_key or settings.OPENAI_API_KEY)
        print("ðŸ”§ [STEP 6-10] OpenAI client created", file=sys.stderr, flush=True)
        
        # ì œì¡°ì—… ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ì‘ë‹µ í…œí”Œë¦¿ (í´ë°±ìš©)
        print("ðŸ”§ [STEP 6-11] Setting up response templates...", file=sys.stderr, flush=True)
        self.response_templates = {
            "pressure": [
                "ì••ë ¥ ì´ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ë‹¤ìŒ ì¡°ì¹˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:\n1. ì••ë ¥ ì„¼ì„œ ì ê²€\n2. ë°¸ë¸Œ ìƒíƒœ í™•ì¸\n3. ë°°ê´€ ëˆ„ì¶œ ê²€ì‚¬\n4. ì•ˆì „ í”„ë¡œí† ì½œ ì‹¤í–‰",
                "ì••ë ¥ ìƒìŠ¹ ì›ì¸ì„ ë¶„ì„í•œ ê²°ê³¼, ë°¸ë¸Œ ì˜¤ìž‘ë™ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. ì •ë¹„íŒ€ì— ì¦‰ì‹œ ì—°ë½í•˜ì—¬ V-001 ë°¸ë¸Œë¥¼ ì ê²€í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤.",
                "ì••ë ¥ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•œ ê²°ê³¼, ì •ìƒ ë²”ìœ„(1.0-3.5 bar)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê¸´ê¸‰ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
            ],
            "temperature": [
                "ì˜¨ë„ ì„¼ì„œ ì´ìƒì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì ê²€ ì ˆì°¨ë¥¼ ë”°ë¥´ì„¸ìš”:\n1. ì„¼ì„œ ì¼€ì´ë¸” ì—°ê²° ìƒíƒœ í™•ì¸\n2. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ì ê²€\n3. ì£¼ë³€ í™˜ê²½ ì˜¨ë„ ì¸¡ì •",
                "T-002 ì„¼ì„œì˜ íŒ¨í„´ ë¶„ì„ ê²°ê³¼, ì£¼ê¸°ì ì¸ ìŠ¤íŒŒì´í¬ê°€ ë°œê²¬ë©ë‹ˆë‹¤. ì „ê¸°ì  ê°„ì„­ì´ë‚˜ ê¸°ê³„ì  ì§„ë™ì„ í™•ì¸í•´ë³´ì„¸ìš”.",
                "ì˜¨ë„ ì„¼ì„œ êµì²´ë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤. í˜„ìž¬ ì„¼ì„œì˜ ì •í™•ë„ê°€ í—ˆìš© ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤."
            ],
            "general": [
                "ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ìƒíƒœ ì ê²€ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ íŒŒë¼ë¯¸í„°ê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìžˆìœ¼ë‚˜, ì •ê¸° ìœ ì§€ë³´ìˆ˜ê°€ í•„ìš”í•œ ë¶€ë¶„ì´ ìžˆìŠµë‹ˆë‹¤.",
                "ì•¼ê°„ êµëŒ€ ì¤€ë¹„ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ ì ê²€ ê²°ê³¼ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤. ëª¨ë“  ì•ˆì „ ì‹œìŠ¤í…œì´ ì •ìƒ ìž‘ë™ ì¤‘ì´ë©°, íŠ¹ë³„í•œ ì£¼ì˜ì‚¬í•­ì€ ì—†ìŠµë‹ˆë‹¤.",
                "ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ë‹¤ìŒ ì ê²€ ì¼ì •ì— ë§žì¶° ì˜ˆë°© ì •ë¹„ë¥¼ ì‹¤ì‹œí•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤."
            ]
        }
        print("âœ… [STEP 6-12] PrismLLMService initialization completed successfully!", file=sys.stderr, flush=True)
    
    def generate(self, request: LLMGenerationRequest) -> str:
        """
        OpenAI-Compatible vLLM ì„œë²„ì˜ chat completions ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ìƒì„±
        - messages ë˜ëŠ” extra_body["messages"]ê°€ ë°˜ë“œì‹œ ì¡´ìž¬í•´ì•¼ í•©ë‹ˆë‹¤
        """
        try:
            messages = request.messages or ((request.extra_body or {}).get("messages") if request.extra_body else None)
            if not messages:
                raise ValueError("PrismLLMService.generate: 'messages' is required for chat completions.")

            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=request.temperature,
                max_tokens=request.max_tokens,
                stop=request.stop,
                extra_body=request.extra_body or None,
            )
            return resp.choices[0].message.content or ""
        except Exception as e:
            print(f"âš ï¸  OpenAI-compatible chat í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._generate_fallback_response(request)
    
    def _generate_fallback_response(self, request: LLMGenerationRequest) -> str:
        """
        ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ ìƒì„±
        """
        if self.simulate_delay:
            time.sleep(random.uniform(0.5, 2.0))
        
        prompt = (request.prompt or "").lower()
        
        # í”„ë¡¬í”„íŠ¸ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µ ì„ íƒ
        if "ì••ë ¥" in prompt or "pressure" in prompt:
            responses = self.response_templates["pressure"]
        elif "ì˜¨ë„" in prompt or "temperature" in prompt:
            responses = self.response_templates["temperature"]
        else:
            responses = self.response_templates["general"]
        
        base_response = random.choice(responses)
        
        enhanced_response = f"""## PRISM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‘ë‹µ (í´ë°± ëª¨ë“œ)

{base_response}

### ê¶Œìž¥ ì¡°ì¹˜ì‚¬í•­:
- ì¦‰ì‹œ í•´ë‹¹ ì‹œìŠ¤í…œ ë‹´ë‹¹ìžì—ê²Œ ë³´ê³ 
- ì•ˆì „ í”„ë¡œí† ì½œ ì¤€ìˆ˜
- ì¡°ì¹˜ ê²°ê³¼ë¥¼ ì‹œìŠ¤í…œì— ê¸°ë¡

### ì¶”ê°€ ì •ë³´:
- ë¶„ì„ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}
- ëª¨ë¸: {self.model_name} (í´ë°± ëª¨ë“œ)
- ì‹ ë¢°ë„: {random.randint(85, 98)}%

---
*ì´ ì‘ë‹µì€ PRISM-Core ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í´ë°± ëª¨ë“œì— ì˜í•´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*"""

        return enhanced_response
    
    def _map_tools_to_openai(self, tool_list: List[str]) -> List[Dict[str, Any]]:
        """ToolRegistryì˜ ë„êµ¬ë“¤ì„ OpenAI tools í¬ë§·ìœ¼ë¡œ ë§¤í•‘"""
        tools: List[Dict[str, Any]] = []
        for tool in tool_list:
            total_tool_for_agent = self.tool_registry.get_tool(tool)
            # check all tool names in tool_list exist in total_tool_for_agent
            if all(tool_name in total_tool_for_agent for tool_name in tool_list):
                tools.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": getattr(tool, "description", ""),
                        "parameters": getattr(tool, "parameters_schema", {}),
                    },
                })
            else:
                warning(f"ë„êµ¬ '{tool}'ëŠ” í•´ë‹¹ ì—ì´ì „íŠ¸ì— ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return tools
    
    def register_agent(self, agent: Agent) -> bool:
        """
        PRISM-Core ì„œë¹„ìŠ¤ì— ì—ì´ì „íŠ¸ ë“±ë¡
        asdf
        """
        try:
            # Pre-check: if agent already exists on server, skip remote registration
            try:
                existing = self.get_agents() or []
                if any((a.get("name") == agent.name) for a in existing if isinstance(a, dict)):
                    print(f"â„¹ï¸  ì—ì´ì „íŠ¸ '{agent.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    return True
            except Exception:
                pass

            url = f"{self.llm_service_url}/api/agents"
            print(f"url: {url}")
            payload = {
                "name": agent.name,
                "description": agent.description,
                "role_prompt": agent.role_prompt,
                "tools": agent.tools
            }
            response = self.session.post(url, json=payload)
            if response.status_code == 400:
                # Treat duplicate as success
                try:
                    detail = response.json()
                    print(f"detail: {detail}")
                except Exception:
                    detail = {"detail": response.text}
                if isinstance(detail, dict) and ("already" in str(detail.get("detail", ""))):
                    print(f"â„¹ï¸  ì—ì´ì „íŠ¸ '{agent.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    return True
            response.raise_for_status()
            print(f"âœ… ì—ì´ì „íŠ¸ '{agent.name}' ë“±ë¡ ì„±ê³µ")
            return True
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ '{agent.name}' ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ë“±ë¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def register_tool(self, tool: BaseTool) -> bool:
        """
        PRISM-Core ì„œë¹„ìŠ¤ì— ë„êµ¬ ë“±ë¡
        """
        import sys
        try:
            print(f"ðŸ”§ [TOOL-REG-1] Starting tool registration for '{tool.name}'", file=sys.stderr, flush=True)
            # Pre-check: if tool already exists on server, skip remote registration
            try:
                print(f"ðŸ”§ [TOOL-REG-2] Checking existing tools via get_tools()", file=sys.stderr, flush=True)
                existing = self.get_tools() or []
                print(f"ðŸ”§ [TOOL-REG-3] Found {len(existing)} existing tools", file=sys.stderr, flush=True)
                if any((t.get("name") == tool.name) for t in existing if isinstance(t, dict)):
                    print(f"â„¹ï¸  ë„êµ¬ '{tool.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    try:
                        self.tool_registry.register_tool(tool)
                    except Exception:
                        pass
                    return True
            except Exception:
                # If listing fails, proceed to try registering
                pass

            url = f"{self.llm_service_url}/api/tools"
            payload = {
                "name": tool.name,
                "description": tool.description,
                "parameters_schema": tool.parameters_schema,
                "tool_type": tool.tool_type # api, calculation, function, database
            }
            response = self.session.post(url, json=payload)
            # Treat duplicate registration as success
            if response.status_code == 400:
                try:
                    detail = response.json()
                except Exception:
                    detail = {"detail": response.text}
                if isinstance(detail, dict) and "already registered" in str(detail.get("detail", "")):
                    print(f"â„¹ï¸  ë„êµ¬ '{tool.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    try:
                        self.tool_registry.register_tool(tool)
                    except Exception:
                        pass
                    return True
            response.raise_for_status()
            print(f"âœ… ë„êµ¬ '{tool.name}' ë“±ë¡ ì„±ê³µ")
            # ë¡œì»¬ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ë„ ë“±ë¡
            self.tool_registry.register_tool(tool)
            return True
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ '{tool.name}' ë“±ë¡ ì‹¤íŒ¨: {e}")
            try:
                self.tool_registry.register_tool(tool)
                print(f"  ðŸ’¡ ë¡œì»¬ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ëŠ” ë“±ë¡ë¨")
            except:
                pass
            return False
        except Exception as e:
            print(f"âŒ ë„êµ¬ ë“±ë¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def assign_tools_to_agent(self, agent_name: str, tool_names: List[str]) -> bool:
        """
        ì—ì´ì „íŠ¸ì— ë„êµ¬ í• ë‹¹
        """
        try:
            url = f"{self.llm_service_url}/api/agents/{agent_name}/tools"
            payload = {"agent_name": agent_name, "tool_names": tool_names}
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            print(f"âœ… ì—ì´ì „íŠ¸ '{agent_name}'ì— ë„êµ¬ í• ë‹¹ ì„±ê³µ: {', '.join(tool_names)}")
            return True
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ í• ë‹¹ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"âŒ ë„êµ¬ í• ë‹¹ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def get_agents(self) -> List[Dict[str, Any]]:
        try:
            url = f"{self.llm_service_url}/api/agents"
            response = self.session.get(url)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return []
    
    def get_tools(self) -> List[Dict[str, Any]]:
        import sys
        try:
            url = f"{self.llm_service_url}/api/tools"
            print(f"ðŸ”§ [GET-TOOLS-1] Requesting tools from: {url}", file=sys.stderr, flush=True)
            response = self.session.get(url, timeout=10)
            print(f"ðŸ”§ [GET-TOOLS-2] Response status: {response.status_code}", file=sys.stderr, flush=True)
            response.raise_for_status()
            result = response.json()
            print(f"ðŸ”§ [GET-TOOLS-3] Successfully retrieved {len(result)} tools", file=sys.stderr, flush=True)
            return result
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", file=sys.stderr, flush=True)
            return []
        except Exception as e:
            print(f"âŒ ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", file=sys.stderr, flush=True)
            return []
    
    def setup_complete_system(self, agents: List[Agent], tools: List[BaseTool]) -> bool:
        print(f"ðŸš€ ì™„ì „í•œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì„¤ì • ì‹œìž‘")
        print(f"  ðŸ“ ì—ì´ì „íŠ¸: {len(agents)}ê°œ")
        print(f"  ðŸ› ï¸  ë„êµ¬: {len(tools)}ê°œ")
        success_count = 0
        total_operations = len(tools) + len(agents)
        print(f"\nðŸ”§ 1ë‹¨ê³„: ë„êµ¬ ë“±ë¡")
        for tool in tools:
            if self.register_tool(tool):
                success_count += 1
        print(f"\nðŸ¤– 2ë‹¨ê³„: ì—ì´ì „íŠ¸ ë“±ë¡")
        for agent in agents:
            if self.register_agent(agent):
                success_count += 1
                if agent.tools:
                    self.assign_tools_to_agent(agent.name, agent.tools)
        success_rate = (success_count / total_operations) * 100 if total_operations > 0 else 0
        print(f"\nðŸ“Š ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ:")
        print(f"  âœ… ì„±ê³µ: {success_count}/{total_operations} ({success_rate:.1f}%)")
        return success_count == total_operations
    
    async def invoke_agent(self, agent, request: AgentInvokeRequest) -> AgentResponse:
        """
        ì§ì ‘ vLLMì„ í†µí•´ ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤ (ë¬´í•œ ìˆœí™˜ ë°©ì§€).
        """
        import sys
        try:
            # agentê°€ Agent ê°ì²´ì¸ ê²½ìš° ì´ë¦„ ì¶”ì¶œ, ë¬¸ìžì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            agent_name = agent.name if hasattr(agent, 'name') else str(agent)
            print(f"ðŸ”§ [INVOKE-1] Starting direct vLLM agent invocation: {agent_name}", file=sys.stderr, flush=True)
            
            # ë¬´í•œ ìˆœí™˜ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì§ì ‘ vLLM í˜¸ì¶œ
            print(f"ðŸ”§ [INVOKE-2] Using direct vLLM call to avoid infinite recursion", file=sys.stderr, flush=True)
            
            print(f"ðŸ”§ [INVOKE-3] Calling direct vLLM via OpenAI client...", file=sys.stderr, flush=True)
            # ì§ì ‘ vLLM í˜¸ì¶œ (ë¬´í•œ ìˆœí™˜ ë°©ì§€)
            completion = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": request.prompt}],
                max_tokens=request.max_tokens,
                temperature=request.temperature,
                stop=request.stop
            )
            response_text = completion.choices[0].message.content
            print(f"ðŸ”§ [INVOKE-4] Direct vLLM response received", file=sys.stderr, flush=True)
            
            print(f"âœ… ì—ì´ì „íŠ¸ '{agent_name}' í˜¸ì¶œ ì™„ë£Œ (ì‘ë‹µ ê¸¸ì´: {len(response_text)})")
            
            return AgentResponse(
                text=response_text,
                tools_used=[],
                tool_results=[],
                metadata={"agent_name": agent_name, "direct_vllm": True}
            )
            
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ '{agent_name}' í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return AgentResponse(
                text=f"ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}",
                tools_used=[],
                tool_results=[],
                metadata={"error": str(e)}
            )
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ í˜¸ì¶œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return AgentResponse(
                text=f"ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}",
                tools_used=[],
                tool_results=[],
                metadata={"error": str(e)}
            )
    
    def _build_agent_prompt(self, agent, user_prompt: str, tool_results: List[Dict]) -> str:
        """(Deprecated) ë¬¸ìžì—´ í”„ë¡¬í”„íŠ¸ ë°©ì‹ ìœ ì§€ìš© - í˜„ìž¬ëŠ” chat ê¸°ë°˜ ì‚¬ìš©"""
        prompt_parts = [agent.role_prompt, f"\nì‚¬ìš©ìž ìš”ì²­: {user_prompt}"]
        if tool_results:
            prompt_parts.append("\n\në„êµ¬ ì‹¤í–‰ ê²°ê³¼:")
            for result in tool_results:
                prompt_parts.append(f"- {result['tool']}: {result['message']}")
                if result['result']:
                    prompt_parts.append(f"  ë°ì´í„°: {str(result['result'])[:200]}...")
        prompt_parts.append("\n\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìžì—ê²Œ ì¢…í•©ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.")
        return "\n".join(prompt_parts)
    
    def get_model_info(self) -> Dict[str, Any]:
        return {
            "name": self.model_name,
            "type": "prism-llm",
            "version": "1.0.0",
            "description": "PRISM-Core ì „ìš© ì œì¡°ì—… íŠ¹í™” LLM ì„œë¹„ìŠ¤",
            "capabilities": [
                "manufacturing_analysis",
                "safety_assessment", 
                "maintenance_planning",
                "korean_language"
            ]
        } 