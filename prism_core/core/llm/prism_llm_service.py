from logging import warning
from typing import Any, Dict, List, Optional
import random
import time
import requests
import json
import os
import socket
from openai import OpenAI

from .base import BaseLLMService
from .schemas import LLMGenerationRequest, AgentInvokeRequest, AgentResponse, Agent
from ..tools import ToolRegistry, ToolRequest, ToolResponse, BaseTool, ToolRegistrationRequest
from ..config import settings


class PrismLLMService(BaseLLMService):
    """
    PRISM-Core ì „ìš© LLM ì„œë¹„ìŠ¤ (OpenAI-Compatible vLLM ì„œë²„ í´ë¼ì´ì–¸íŠ¸)
    
    - chat completions ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€/íˆ´ ê¸°ë°˜ ëŒ€í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•  ê²½ìš° ê°„ë‹¨í•œ íˆ´ ì½œ ë£¨í”„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ì—ì´ì „íŠ¸/ë„êµ¬ ë“±ë¡ì€ ê¸°ì¡´ PRISM-Core APIë¥¼ í†µí•´ ì§€ì†
    """
    
    def __init__(self, 
                 model_name: Optional[str] = None, 
                 simulate_delay: bool = False, 
                 tool_registry: Optional[ToolRegistry] = None,
                 llm_service_url: str = "http://localhost:8000",
                 agent_name: str = "orchestration_agent",
                 openai_base_url: Optional[str] = None,
                 api_key: Optional[str] = None):
        """
        PrismLLMService ì´ˆê¸°í™”
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ VLLM_MODEL í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” settings.model_name ì‚¬ìš©)
            simulate_delay: í…ŒìŠ¤íŠ¸ìš© ì‘ë‹µ ì§€ì—° ì—¬ë¶€
            tool_registry: ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (invoke ê¸°ëŠ¥ìš©)
            llm_service_url: PRISM-Core API URL (ì—ì´ì „íŠ¸/ë„êµ¬ ë“±ë¡ì— ì‚¬ìš©)
            agent_name: ê¸°ë³¸ ì—ì´ì „íŠ¸ ì´ë¦„
            openai_base_url: vLLM OpenAI-compatible ì„œë²„ base URL (ì˜ˆ: http://host:8001/v1)
            api_key: OpenAI í˜¸í™˜ API í‚¤ (ê¸°ë³¸ì€ EMPTY)
        """
        import sys
        print("ðŸ”§ [STEP 6-1] Starting PrismLLMService initialization...", file=sys.stderr, flush=True)
        
        # ëª¨ë¸ëª… í•´ì„: ìš°ì„ ìˆœìœ„ model_name arg > env VLLM_MODEL > settings.model_name
        resolved_model = model_name or os.getenv("VLLM_MODEL") or settings.model_name
        self.model_name = resolved_model
        print(f"ðŸ”§ [STEP 6-2] Model name resolved: {self.model_name}", file=sys.stderr, flush=True)
        
        self.simulate_delay = simulate_delay
        print("ðŸ”§ [STEP 6-3] Creating tool registry...", file=sys.stderr, flush=True)
        self.tool_registry = tool_registry or ToolRegistry()
        print("ðŸ”§ [STEP 6-4] Tool registry created", file=sys.stderr, flush=True)
        
        self.llm_service_url = llm_service_url.rstrip('/')
        self.agent_name = agent_name
        print("ðŸ”§ [STEP 6-5] Creating requests session...", file=sys.stderr, flush=True)
        self.session = requests.Session()
        print("ðŸ”§ [STEP 6-6] Requests session created", file=sys.stderr, flush=True)

        # OpenAI-compatible vLLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        print("ðŸ”§ [STEP 6-7] Setting up OpenAI client...", file=sys.stderr, flush=True)
        base_url = (openai_base_url or settings.VLLM_OPENAI_BASE_URL).rstrip('/')
        if not base_url.endswith("/v1"):
            base_url = f"{base_url}/v1"
        print(f"ðŸ”§ [STEP 6-8] Base URL: {base_url}", file=sys.stderr, flush=True)
        print(f"ðŸ”§ [STEP 6-9] API Key: {'***' if (api_key or settings.OPENAI_API_KEY) else 'None'}", file=sys.stderr, flush=True)
        
        self.client = OpenAI(base_url=base_url, api_key=api_key or settings.OPENAI_API_KEY)
        print("ðŸ”§ [STEP 6-10] OpenAI client created", file=sys.stderr, flush=True)
        
        # ì œì¡°ì—… ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ì‘ë‹µ í…œí”Œë¦¿ (í´ë°±ìš©)
        print("ðŸ”§ [STEP 6-11] Setting up response templates...", file=sys.stderr, flush=True)
        self.response_templates = {
            "pressure": [
                "ì••ë ¥ ì´ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ë‹¤ìŒ ì¡°ì¹˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:\n1. ì••ë ¥ ì„¼ì„œ ì ê²€\n2. ë°¸ë¸Œ ìƒíƒœ í™•ì¸\n3. ë°°ê´€ ëˆ„ì¶œ ê²€ì‚¬\n4. ì•ˆì „ í”„ë¡œí† ì½œ ì‹¤í–‰",
                "ì••ë ¥ ìƒìŠ¹ ì›ì¸ì„ ë¶„ì„í•œ ê²°ê³¼, ë°¸ë¸Œ ì˜¤ìž‘ë™ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. ì •ë¹„íŒ€ì— ì¦‰ì‹œ ì—°ë½í•˜ì—¬ V-001 ë°¸ë¸Œë¥¼ ì ê²€í•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤.",
                "ì••ë ¥ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•œ ê²°ê³¼, ì •ìƒ ë²”ìœ„(1.0-3.5 bar)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê¸´ê¸‰ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
            ],
            "temperature": [
                "ì˜¨ë„ ì„¼ì„œ ì´ìƒì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì ê²€ ì ˆì°¨ë¥¼ ë”°ë¥´ì„¸ìš”:\n1. ì„¼ì„œ ì¼€ì´ë¸” ì—°ê²° ìƒíƒœ í™•ì¸\n2. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ì ê²€\n3. ì£¼ë³€ í™˜ê²½ ì˜¨ë„ ì¸¡ì •",
                "T-002 ì„¼ì„œì˜ íŒ¨í„´ ë¶„ì„ ê²°ê³¼, ì£¼ê¸°ì ì¸ ìŠ¤íŒŒì´í¬ê°€ ë°œê²¬ë©ë‹ˆë‹¤. ì „ê¸°ì  ê°„ì„­ì´ë‚˜ ê¸°ê³„ì  ì§„ë™ì„ í™•ì¸í•´ë³´ì„¸ìš”.",
                "ì˜¨ë„ ì„¼ì„œ êµì²´ë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤. í˜„ìž¬ ì„¼ì„œì˜ ì •í™•ë„ê°€ í—ˆìš© ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤."
            ],
            "general": [
                "ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ìƒíƒœ ì ê²€ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ íŒŒë¼ë¯¸í„°ê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìžˆìœ¼ë‚˜, ì •ê¸° ìœ ì§€ë³´ìˆ˜ê°€ í•„ìš”í•œ ë¶€ë¶„ì´ ìžˆìŠµë‹ˆë‹¤.",
                "ì•¼ê°„ êµëŒ€ ì¤€ë¹„ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ ì ê²€ ê²°ê³¼ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤. ëª¨ë“  ì•ˆì „ ì‹œìŠ¤í…œì´ ì •ìƒ ìž‘ë™ ì¤‘ì´ë©°, íŠ¹ë³„í•œ ì£¼ì˜ì‚¬í•­ì€ ì—†ìŠµë‹ˆë‹¤.",
                "ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ë‹¤ìŒ ì ê²€ ì¼ì •ì— ë§žì¶° ì˜ˆë°© ì •ë¹„ë¥¼ ì‹¤ì‹œí•˜ì‹œê¸° ë°”ëžë‹ˆë‹¤."
            ]
        }
        print("âœ… [STEP 6-12] PrismLLMService initialization completed successfully!", file=sys.stderr, flush=True)
    
    def generate(self, request: LLMGenerationRequest) -> str:
        """
        OpenAI-Compatible vLLM ì„œë²„ì˜ chat completions ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ìƒì„±
        - messages ë˜ëŠ” extra_body["messages"]ê°€ ë°˜ë“œì‹œ ì¡´ìž¬í•´ì•¼ í•©ë‹ˆë‹¤
        """
        try:
            messages = request.messages or ((request.extra_body or {}).get("messages") if request.extra_body else None)
            if not messages:
                raise ValueError("PrismLLMService.generate: 'messages' is required for chat completions.")

            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=request.temperature,
                max_tokens=request.max_tokens,
                stop=request.stop,
                extra_body=request.extra_body or None,
            )
            return resp.choices[0].message.content or ""
        except Exception as e:
            print(f"âš ï¸  OpenAI-compatible chat í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return self._generate_fallback_response(request)
    
    def _generate_fallback_response(self, request: LLMGenerationRequest) -> str:
        """
        ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ ìƒì„±
        """
        if self.simulate_delay:
            time.sleep(random.uniform(0.5, 2.0))
        
        prompt = (request.prompt or "").lower()
        
        # í”„ë¡¬í”„íŠ¸ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µ ì„ íƒ
        if "ì••ë ¥" in prompt or "pressure" in prompt:
            responses = self.response_templates["pressure"]
        elif "ì˜¨ë„" in prompt or "temperature" in prompt:
            responses = self.response_templates["temperature"]
        else:
            responses = self.response_templates["general"]
        
        base_response = random.choice(responses)
        
        enhanced_response = f"""## PRISM ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‘ë‹µ (í´ë°± ëª¨ë“œ)

{base_response}

### ê¶Œìž¥ ì¡°ì¹˜ì‚¬í•­:
- ì¦‰ì‹œ í•´ë‹¹ ì‹œìŠ¤í…œ ë‹´ë‹¹ìžì—ê²Œ ë³´ê³ 
- ì•ˆì „ í”„ë¡œí† ì½œ ì¤€ìˆ˜
- ì¡°ì¹˜ ê²°ê³¼ë¥¼ ì‹œìŠ¤í…œì— ê¸°ë¡

### ì¶”ê°€ ì •ë³´:
- ë¶„ì„ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}
- ëª¨ë¸: {self.model_name} (í´ë°± ëª¨ë“œ)
- ì‹ ë¢°ë„: {random.randint(85, 98)}%

---
*ì´ ì‘ë‹µì€ PRISM-Core ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í´ë°± ëª¨ë“œì— ì˜í•´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*"""

        return enhanced_response
    
    def _map_tools_to_openai(self, tool_list: List[str]) -> List[Dict[str, Any]]:
        """ToolRegistryì˜ ë„êµ¬ë“¤ì„ OpenAI tools í¬ë§·ìœ¼ë¡œ ë§¤í•‘"""
        tools: List[Dict[str, Any]] = []
        for tool in tool_list:
            total_tool_for_agent = self.tool_registry.get_tool(tool)
            # check all tool names in tool_list exist in total_tool_for_agent
            if all(tool_name in total_tool_for_agent for tool_name in tool_list):
                tools.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": getattr(tool, "description", ""),
                        "parameters": getattr(tool, "parameters_schema", {}),
                    },
                })
            else:
                warning(f"ë„êµ¬ '{tool}'ëŠ” í•´ë‹¹ ì—ì´ì „íŠ¸ì— ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return tools
    
    def register_agent(self, agent: Agent) -> bool:
        """
        PRISM-Core ì„œë¹„ìŠ¤ì— ì—ì´ì „íŠ¸ ë“±ë¡
        asdf
        """
        try:
            # Pre-check: if agent already exists on server, skip remote registration
            try:
                existing = self.get_agents() or []
                if any((a.get("name") == agent.name) for a in existing if isinstance(a, dict)):
                    print(f"â„¹ï¸  ì—ì´ì „íŠ¸ '{agent.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    return True
            except Exception:
                pass

            url = f"{self.llm_service_url}/api/agents"
            print(f"url: {url}")
            payload = {
                "name": agent.name,
                "description": agent.description,
                "role_prompt": agent.role_prompt,
                "tools": agent.tools
            }
            response = self.session.post(url, json=payload)
            if response.status_code == 400:
                # Treat duplicate as success
                try:
                    detail = response.json()
                    print(f"detail: {detail}")
                except Exception:
                    detail = {"detail": response.text}
                if isinstance(detail, dict) and ("already" in str(detail.get("detail", ""))):
                    print(f"â„¹ï¸  ì—ì´ì „íŠ¸ '{agent.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    return True
            response.raise_for_status()
            print(f"âœ… ì—ì´ì „íŠ¸ '{agent.name}' ë“±ë¡ ì„±ê³µ")
            return True
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ '{agent.name}' ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ë“±ë¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def register_tool(self, tool: BaseTool) -> bool:
        """
        PRISM-Core ì„œë¹„ìŠ¤ì— ë„êµ¬ ë“±ë¡
        """
        import sys
        try:
            print(f"ðŸ”§ [TOOL-REG-1] Starting tool registration for '{tool.name}'", file=sys.stderr, flush=True)
            # Pre-check: if tool already exists on server, skip remote registration
            try:
                print(f"ðŸ”§ [TOOL-REG-2] Checking existing tools via get_tools()", file=sys.stderr, flush=True)
                existing = self.get_tools() or []
                print(f"ðŸ”§ [TOOL-REG-3] Found {len(existing)} existing tools", file=sys.stderr, flush=True)
                if any((t.get("name") == tool.name) for t in existing if isinstance(t, dict)):
                    print(f"â„¹ï¸  ë„êµ¬ '{tool.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    try:
                        self.tool_registry.register_tool(tool)
                    except Exception:
                        pass
                    return True
            except Exception:
                # If listing fails, proceed to try registering
                pass

            url = f"{self.llm_service_url}/api/tools"
            payload = {
                "name": tool.name,
                "description": tool.description,
                "parameters_schema": tool.parameters_schema,
                "tool_type": tool.tool_type # api, calculation, function, database
            }
            response = self.session.post(url, json=payload)
            # Treat duplicate registration as success
            if response.status_code == 400:
                try:
                    detail = response.json()
                except Exception:
                    detail = {"detail": response.text}
                if isinstance(detail, dict) and "already registered" in str(detail.get("detail", "")):
                    print(f"â„¹ï¸  ë„êµ¬ '{tool.name}'ëŠ” ì´ë¯¸ ì„œë²„ì— ë“±ë¡ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                    try:
                        self.tool_registry.register_tool(tool)
                    except Exception:
                        pass
                    return True
            response.raise_for_status()
            print(f"âœ… ë„êµ¬ '{tool.name}' ë“±ë¡ ì„±ê³µ")
            # ë¡œì»¬ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ë„ ë“±ë¡
            self.tool_registry.register_tool(tool)
            return True
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ '{tool.name}' ë“±ë¡ ì‹¤íŒ¨: {e}")
            try:
                self.tool_registry.register_tool(tool)
                print(f"  ðŸ’¡ ë¡œì»¬ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ëŠ” ë“±ë¡ë¨")
            except:
                pass
            return False
        except Exception as e:
            print(f"âŒ ë„êµ¬ ë“±ë¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def assign_tools_to_agent(self, agent_name: str, tool_names: List[str]) -> bool:
        """
        ì—ì´ì „íŠ¸ì— ë„êµ¬ í• ë‹¹
        """
        try:
            url = f"{self.llm_service_url}/api/agents/{agent_name}/tools"
            payload = {"agent_name": agent_name, "tool_names": tool_names}
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            print(f"âœ… ì—ì´ì „íŠ¸ '{agent_name}'ì— ë„êµ¬ í• ë‹¹ ì„±ê³µ: {', '.join(tool_names)}")
            return True
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ í• ë‹¹ ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            print(f"âŒ ë„êµ¬ í• ë‹¹ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def get_agents(self) -> List[Dict[str, Any]]:
        try:
            url = f"{self.llm_service_url}/api/agents"
            response = self.session.get(url)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return []
    
    def get_tools(self) -> List[Dict[str, Any]]:
        import sys
        try:
            url = f"{self.llm_service_url}/api/tools"
            print(f"ðŸ”§ [GET-TOOLS-1] Requesting tools from: {url}", file=sys.stderr, flush=True)
            response = self.session.get(url, timeout=10)
            print(f"ðŸ”§ [GET-TOOLS-2] Response status: {response.status_code}", file=sys.stderr, flush=True)
            response.raise_for_status()
            result = response.json()
            print(f"ðŸ”§ [GET-TOOLS-3] Successfully retrieved {len(result)} tools", file=sys.stderr, flush=True)
            return result
        except requests.RequestException as e:
            print(f"âŒ ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", file=sys.stderr, flush=True)
            return []
        except Exception as e:
            print(f"âŒ ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", file=sys.stderr, flush=True)
            return []
    
    def setup_complete_system(self, agents: List[Agent], tools: List[BaseTool]) -> bool:
        print(f"ðŸš€ ì™„ì „í•œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì„¤ì • ì‹œìž‘")
        print(f"  ðŸ“ ì—ì´ì „íŠ¸: {len(agents)}ê°œ")
        print(f"  ðŸ› ï¸  ë„êµ¬: {len(tools)}ê°œ")
        success_count = 0
        total_operations = len(tools) + len(agents)
        print(f"\nðŸ”§ 1ë‹¨ê³„: ë„êµ¬ ë“±ë¡")
        for tool in tools:
            if self.register_tool(tool):
                success_count += 1
        print(f"\nðŸ¤– 2ë‹¨ê³„: ì—ì´ì „íŠ¸ ë“±ë¡")
        for agent in agents:
            if self.register_agent(agent):
                success_count += 1
                if agent.tools:
                    self.assign_tools_to_agent(agent.name, agent.tools)
        success_rate = (success_count / total_operations) * 100 if total_operations > 0 else 0
        print(f"\nðŸ“Š ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ:")
        print(f"  âœ… ì„±ê³µ: {success_count}/{total_operations} ({success_rate:.1f}%)")
        return success_count == total_operations
    
    async def invoke_agent(self, agent, request: AgentInvokeRequest) -> AgentResponse:
        """
        vLLMì„ í†µí•´ ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ë©° automatic function callingì„ ì§€ì›í•©ë‹ˆë‹¤.
        """
        import sys
        import json
        try:
            # agentê°€ Agent ê°ì²´ì¸ ê²½ìš° ì´ë¦„ ì¶”ì¶œ, ë¬¸ìžì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            agent_name = agent.name if hasattr(agent, 'name') else str(agent)
            print(f"ðŸ”§ [INVOKE-1] Starting agent invocation with function calling: {agent_name}", file=sys.stderr, flush=True)
            
            # Agent ë„êµ¬ ëª©ë¡ í™•ì¸
            agent_tools = getattr(agent, 'tools', []) if hasattr(agent, 'tools') else []
            use_tools = request.use_tools and len(agent_tools) > 0
            
            print(f"ðŸ”§ [INVOKE-2] Agent tools: {agent_tools}, Use tools: {use_tools}", file=sys.stderr, flush=True)
            
            if use_tools:
                # Function calling ì§€ì› ëª¨ë“œ
                response = await self._invoke_agent_with_function_calling(agent, request)
            else:
                # ê¸°ë³¸ ëª¨ë“œ (ë„êµ¬ ì—†ìŒ)
                response = await self._invoke_agent_basic(agent, request)
            
            # session_idë¥¼ ì‘ë‹µì— í¬í•¨
            if request.session_id:
                response.session_id = request.session_id
                if response.metadata:
                    response.metadata["session_id"] = request.session_id
                else:
                    response.metadata = {"session_id": request.session_id}
            
            return response
            
        except requests.RequestException as e:
            print(f"âŒ ì—ì´ì „íŠ¸ '{agent_name}' í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return AgentResponse(
                text=f"ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}",
                tools_used=[],
                tool_results=[],
                metadata={"error": str(e), "session_id": getattr(request, 'session_id', None)}
            )
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ í˜¸ì¶œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return AgentResponse(
                text=f"ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}",
                tools_used=[],
                tool_results=[],
                metadata={"error": str(e), "session_id": getattr(request, 'session_id', None)}
            )

    async def _invoke_agent_basic(self, agent, request: AgentInvokeRequest) -> AgentResponse:
        """ê¸°ë³¸ ì—ì´ì „íŠ¸ í˜¸ì¶œ (ë„êµ¬ ì—†ìŒ)"""
        import sys
        agent_name = agent.name if hasattr(agent, 'name') else str(agent)
        print(f"ðŸ”§ [INVOKE-BASIC-1] Basic agent invocation: {agent_name}", file=sys.stderr, flush=True)
        
        # ì§ì ‘ vLLM í˜¸ì¶œ (ë¬´í•œ ìˆœí™˜ ë°©ì§€)
        completion = self.client.chat.completions.create(
            model=self.model_name,
            messages=[{"role": "user", "content": request.prompt}],
            max_tokens=request.max_tokens,
            temperature=request.temperature,
            stop=request.stop,
            extra_body=request.extra_body if request.extra_body else {"chat_template_kwargs": {"enable_thinking": False}}
        )
        response_text = completion.choices[0].message.content
        print(f"ðŸ”§ [INVOKE-BASIC-2] Basic response received", file=sys.stderr, flush=True)
        
        metadata = {"agent_name": agent_name, "mode": "basic"}
        if request.session_id:
            metadata["session_id"] = request.session_id
        
        return AgentResponse(
            text=response_text,
            tools_used=[],
            tool_results=[],
            metadata=metadata
        )

    async def _invoke_agent_with_function_calling(self, agent, request: AgentInvokeRequest) -> AgentResponse:
        """Function callingì„ ì§€ì›í•˜ëŠ” ì—ì´ì „íŠ¸ í˜¸ì¶œ"""
        import sys
        import json
        
        agent_name = agent.name if hasattr(agent, 'name') else str(agent)
        print(f"ðŸ”§ [INVOKE-FC-1] Function calling agent invocation: {agent_name}", file=sys.stderr, flush=True)
        
        # ì—ì´ì „íŠ¸ì˜ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        agent_tools = getattr(agent, 'tools', [])
        available_tools = []
        tools_used = []
        tool_results = []
        
        # ë„êµ¬ ìŠ¤í‚¤ë§ˆ ìƒì„±
        for tool_name in agent_tools:
            tool = self.tool_registry.get_tool(tool_name)
            if tool:
                tool_schema = {
                    "type": "function",
                    "function": {
                        "name": tool_name,
                        "description": tool.description,
                        "parameters": tool.parameters_schema
                    }
                }
                available_tools.append(tool_schema)
        
        print(f"ðŸ”§ [INVOKE-FC-2] Available tools: {len(available_tools)}", file=sys.stderr, flush=True)
        
        # ëŒ€í™” ë©”ì‹œì§€ ì¤€ë¹„
        messages = [
            {"role": "system", "content": getattr(agent, 'role_prompt', '')},
            {"role": "user", "content": request.prompt}
        ]
        
        # Function calling ë£¨í”„
        max_iterations = request.max_tool_calls
        for iteration in range(max_iterations):
            print(f"ðŸ”§ [INVOKE-FC-3-{iteration+1}] Function calling iteration {iteration+1}/{max_iterations}", file=sys.stderr, flush=True)
            
            # OpenAI í˜¸ì¶œ (function calling ì§€ì›)
            try:
                completion = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    max_tokens=request.max_tokens,
                    temperature=request.temperature,
                    stop=request.stop,
                    tools=available_tools if available_tools else None,
                    tool_choice="auto" if available_tools else None,
                    extra_body=request.extra_body if request.extra_body else {"chat_template_kwargs": {"enable_thinking": False}}
                )
                
                response_message = completion.choices[0].message
                print(f"ðŸ”§ [INVOKE-FC-4-{iteration+1}] Received response with tool calls: {bool(response_message.tool_calls)}", file=sys.stderr, flush=True)
                
                # ë©”ì‹œì§€ë¥¼ ëŒ€í™”ì— ì¶”ê°€
                messages.append(response_message)
                
                # Tool callsê°€ ìžˆëŠ”ì§€ í™•ì¸
                if response_message.tool_calls:
                    print(f"ðŸ”§ [INVOKE-FC-5-{iteration+1}] Processing {len(response_message.tool_calls)} tool calls", file=sys.stderr, flush=True)
                    
                    # ê° tool call ì‹¤í–‰
                    for tool_call in response_message.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments)
                        
                        print(f"ðŸ”§ [INVOKE-FC-6-{iteration+1}] Executing tool: {tool_name} with args: {tool_args}", file=sys.stderr, flush=True)
                        
                        # ë„êµ¬ ì‹¤í–‰
                        tool = self.tool_registry.get_tool(tool_name)
                        if tool:
                            try:
                                from ..tools.schemas import ToolRequest
                                tool_request = ToolRequest(tool_name=tool_name, parameters=tool_args)
                                tool_response = await tool.execute(tool_request)
                                
                                tools_used.append(tool_name)
                                tool_results.append({
                                    "tool": tool_name,
                                    "arguments": tool_args,
                                    "result": tool_response.result if tool_response.success else None,
                                    "error": tool_response.error_message if not tool_response.success else None,
                                    "success": tool_response.success
                                })
                                
                                # Tool resultë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                                tool_result_content = json.dumps(tool_response.result) if tool_response.success else f"Error: {tool_response.error_message}"
                                messages.append({
                                    "role": "tool",
                                    "tool_call_id": tool_call.id,
                                    "content": tool_result_content
                                })
                                
                                print(f"âœ… Tool '{tool_name}' executed successfully", file=sys.stderr, flush=True)
                                
                            except Exception as e:
                                error_msg = f"Tool execution error: {str(e)}"
                                tool_results.append({
                                    "tool": tool_name,
                                    "arguments": tool_args,
                                    "result": None,
                                    "error": error_msg,
                                    "success": False
                                })
                                
                                messages.append({
                                    "role": "tool",
                                    "tool_call_id": tool_call.id,
                                    "content": error_msg
                                })
                                
                                print(f"âŒ Tool '{tool_name}' execution failed: {error_msg}", file=sys.stderr, flush=True)
                        else:
                            error_msg = f"Tool '{tool_name}' not found"
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": error_msg
                            })
                            print(f"âŒ {error_msg}", file=sys.stderr, flush=True)
                    
                    # ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ ê³„ì†
                    continue
                else:
                    # Tool callsê°€ ì—†ìœ¼ë©´ ì™„ë£Œ
                    final_response = response_message.content
                    print(f"ðŸ”§ [INVOKE-FC-7] Function calling completed with final response", file=sys.stderr, flush=True)
                    
                    return AgentResponse(
                        text=final_response,
                        tools_used=list(set(tools_used)),  # ì¤‘ë³µ ì œê±°
                        tool_results=tool_results,
                        metadata={
                            "agent_name": agent_name,
                            "mode": "function_calling",
                            "iterations": iteration + 1,
                            "tools_available": len(available_tools),
                            "session_id": request.session_id
                        }
                    )
                    
            except Exception as e:
                print(f"âŒ Function calling iteration {iteration+1} failed: {str(e)}", file=sys.stderr, flush=True)
                break
        
        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ë˜ëŠ” ì˜¤ë¥˜ ë°œìƒ
        print(f"ðŸ”§ [INVOKE-FC-8] Function calling completed (max iterations reached)", file=sys.stderr, flush=True)
        
        # ë§ˆì§€ë§‰ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
        if messages and len(messages) > 2:
            last_message = messages[-1]
            final_text = last_message.get("content", "Function calling completed but no final response")
        else:
            final_text = "Function calling process completed"
        
        return AgentResponse(
            text=final_text,
            tools_used=list(set(tools_used)),
            tool_results=tool_results,
            metadata={
                "agent_name": agent_name,
                "mode": "function_calling",
                "iterations": max_iterations,
                "tools_available": len(available_tools),
                "status": "max_iterations_reached",
                "session_id": request.session_id
            }
        )
    
    def _build_agent_prompt(self, agent, user_prompt: str, tool_results: List[Dict]) -> str:
        """(Deprecated) ë¬¸ìžì—´ í”„ë¡¬í”„íŠ¸ ë°©ì‹ ìœ ì§€ìš© - í˜„ìž¬ëŠ” chat ê¸°ë°˜ ì‚¬ìš©"""
        prompt_parts = [agent.role_prompt, f"\nì‚¬ìš©ìž ìš”ì²­: {user_prompt}"]
        if tool_results:
            prompt_parts.append("\n\në„êµ¬ ì‹¤í–‰ ê²°ê³¼:")
            for result in tool_results:
                prompt_parts.append(f"- {result['tool']}: {result['message']}")
                if result['result']:
                    prompt_parts.append(f"  ë°ì´í„°: {str(result['result'])[:200]}...")
        prompt_parts.append("\n\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìžì—ê²Œ ì¢…í•©ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.")
        return "\n".join(prompt_parts)
    
    def get_model_info(self) -> Dict[str, Any]:
        return {
            "name": self.model_name,
            "type": "prism-llm",
            "version": "1.0.0",
            "description": "PRISM-Core ì „ìš© ì œì¡°ì—… íŠ¹í™” LLM ì„œë¹„ìŠ¤",
            "capabilities": [
                "manufacturing_analysis",
                "safety_assessment", 
                "maintenance_planning",
                "korean_language"
            ]
        } 