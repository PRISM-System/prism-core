"""
Memory Search Tool

ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë¡ì„ ê²€ìƒ‰í•˜ëŠ” Toolì…ë‹ˆë‹¤.
Mem0ë¥¼ í™œìš©í•˜ì—¬ ì¥ê¸° ê¸°ì–µê³¼ ê°œì¸í™”ëœ ìƒí˜¸ì‘ìš©ì„ ì œê³µí•©ë‹ˆë‹¤.
PRISM Coreì˜ ê³µí†µ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

import requests
from typing import Dict, Any, List, Optional
from .base import BaseTool
from .schemas import ToolRequest, ToolResponse
from ..config import settings

try:
    from mem0 import Memory
    from mem0.configs.base import MemoryConfig
    MEM0_AVAILABLE = False
except ImportError:
    MEM0_AVAILABLE = False
    print("âš ï¸  Mem0 ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë©”ëª¨ë¦¬ ê²€ìƒ‰ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")


class MemorySearchTool(BaseTool):
    """
    ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë¡ì„ ê²€ìƒ‰í•˜ëŠ” Tool
    
    Mem0ë¥¼ í™œìš©í•œ ê¸°ëŠ¥:
    - ì‚¬ìš©ìë³„ ì¥ê¸° ê¸°ì–µ ê´€ë¦¬
    - ì„¸ì…˜ë³„ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
    - ê°œì¸í™”ëœ ì‘ë‹µ ìƒì„±
    - ì ì‘í˜• í•™ìŠµ ë° ê¸°ì–µ ê°•í™”
    """
    
    def __init__(self, 
                 weaviate_url: Optional[str] = None,
                 openai_base_url: Optional[str] = None,
                 openai_api_key: Optional[str] = None,
                 model_name: Optional[str] = None,
                 encoder_model: Optional[str] = None,
                 vector_dim: Optional[int] = None,
                 client_id: str = "default",
                 class_prefix: str = "Default",
                 tool_type: str = "api"):
        super().__init__(
            name="memory_search",
            description="ì‚¬ìš©ìì˜ ê³¼ê±° ìƒí˜¸ì‘ìš© ê¸°ë¡ì„ ê²€ìƒ‰í•˜ì—¬ ê°œì¸í™”ëœ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤",
            parameters_schema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "ê²€ìƒ‰í•  ì¿¼ë¦¬"},
                    "user_id": {"type": "string", "description": "ì‚¬ìš©ì ID"},
                    "session_id": {"type": "string", "description": "ì„¸ì…˜ ID (ì„ íƒì‚¬í•­)", "default": None},
                    "top_k": {"type": "integer", "description": "ë°˜í™˜í•  ê¸°ë¡ ìˆ˜", "default": 3},
                    "memory_type": {
                        "type": "string", 
                        "enum": ["user", "session", "agent"], 
                        "description": "ë©”ëª¨ë¦¬ íƒ€ì… (ì‚¬ìš©ìë³„, ì„¸ì…˜ë³„, ì—ì´ì „íŠ¸ë³„)", 
                        "default": "user"
                    },
                    "include_context": {
                        "type": "boolean", 
                        "description": "ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨ ì—¬ë¶€", 
                        "default": True
                    }
                },
                "required": ["query", "user_id"]
            },
            tool_type=tool_type
        )
        # ê¸°ì¡´ ì„¤ì • í™œìš©
        self._weaviate_url = weaviate_url or f"http://localhost:18080"  # WEAVIATE_PORT from .env.example
        self._openai_base_url = openai_base_url or settings.VLLM_OPENAI_BASE_URL
        self._openai_api_key = openai_api_key or settings.OPENAI_API_KEY
        self._client_id = client_id
        self._model_name = model_name or settings.VLLM_MODEL
        self._encoder_model = encoder_model or settings.VECTOR_ENCODER_MODEL
        self._vector_dim = vector_dim or settings.VECTOR_DIM
        
        # ë””ë²„ê·¸: íŒŒë¼ë¯¸í„° ì„¤ì • í™•ì¸
        print(f"ğŸ”§ MemorySearchTool ì´ˆê¸°í™” íŒŒë¼ë¯¸í„°:")
        print(f"   - weaviate_url: {self._weaviate_url}")
        print(f"   - openai_base_url: {self._openai_base_url}")
        print(f"   - openai_api_key: {self._openai_api_key[:10]}..." if self._openai_api_key != "EMPTY" else "   - openai_api_key: EMPTY")
        print(f"   - model_name: {self._model_name}")
        print(f"   - encoder_model: {self._encoder_model}")
        print(f"   - vector_dim: {self._vector_dim}")
        print(f"   - client_id: {self._client_id}")
        print(f"   - class_prefix: {class_prefix}")
        
        # ì—ì´ì „íŠ¸ë³„ í´ë˜ìŠ¤ëª… ì„¤ì •
        self._class_history = f"{class_prefix}History"
        
        # Mem0 ì´ˆê¸°í™”
        self._mem0_initialized = False
        self._memory: Optional[Memory] = None
        
        if MEM0_AVAILABLE:
            self._initialize_mem0()

    def _initialize_mem0(self) -> None:
        """Mem0 ì´ˆê¸°í™” - .env.example ì„¤ì • ê¸°ì¤€"""
        try:
            # .env.example ì„¤ì •ì„ í™œìš©í•œ Mem0 ì„¤ì • êµ¬ì„±
            config = MemoryConfig(
                vector_store={
                    "provider": "weaviate",
                    "config": { "cluster_url": self._weaviate_url }
                },
                llm={
                    "provider": "openai",
                    "config": { "api_key": self._openai_api_key if self._openai_api_key != "EMPTY" else "EMPTY", "base_url": self._openai_base_url, "model": self._model_name  # VLLM_MODEL from .env.example }
                    }
                },
                embedder={
                    "provider": "huggingface",
                    # "config": {"model_name": self._embedder_model_name}  # VECTOR_ENCODER_MODEL from .env.example, "device": "cuda"  # GPU ì‚¬ìš© ì‹œ "cuda"ë¡œ ë³€ê²½ ê°€ëŠ¥
                }
            )
            
            # ë””ë²„ê·¸: Mem0 ì„¤ì • í™•ì¸
            # print(f"ğŸ”§ Mem0 ì„¤ì • êµ¬ì„±:")
            # print(f"   - Vector Store: {config.vector_store.provider} ({config.vector_store.config.cluster_url})")
            # print(f"   - LLM: {config.llm.provider} ({config.llm.config["base_url"]})")
            # print(f"   - LLM Model: {config.llm.config['model']}")
            # print(f"   - Embedder: {config.embedder.provider} ({config.embedder.config['model_name']})")
            # print(f"   - Embedder Device: {config.embedder.config['device']}")
            
            # Mem0 ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self._memory = Memory(config=config)
            self._mem0_initialized = True
            
            print("âœ… Mem0 ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (.env.example ì„¤ì • ê¸°ì¤€)")
            print(f"   - Vector Store: Weaviate ({self._weaviate_url})")
            print(f"   - LLM: OpenAI-compatible ({self._openai_base_url})")
            print(f"   - Model: {self._model_name}")
            print(f"   - Embedder: {self._encoder_model}")
            print(f"   - Vector Dim: {self._vector_dim}")
            
        except Exception as e:
            import traceback
            error_info = traceback.extract_tb(e.__traceback__)
            error_line = error_info[-1].lineno
            error_msg = str(e)
            error_type = type(e).__name__
            error_trace = traceback.format_exc()
            
            print(f"âš ï¸  Error occurred on line {error_line}")
            print(f"âš ï¸  Error type: {error_type}")
            print(f"âš ï¸  Error message: {error_msg}")
            print(f"âš ï¸  Full traceback:\n{error_trace}")
            print(f"âš ï¸  Mem0 ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self._mem0_initialized = False

    async def execute(self, request: ToolRequest) -> ToolResponse:
        """Tool ì‹¤í–‰"""
        try:
            params = request.parameters
            query = params["query"]
            user_id = params["user_id"]
            session_id = params.get("session_id", None)
            top_k = params.get("top_k", 3)
            memory_type = params.get("memory_type", "user")
            include_context = params.get("include_context", True)
            
            # Mem0ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ìš°ì„  ì‚¬ìš©
            if self._mem0_initialized and self._memory:
                memories = await self._search_with_mem0(query, user_id, top_k)
            else:
                # Mem0ê°€ ì—†ëŠ” ê²½ìš° Vector DB ì‚¬ìš©
                memories = await self._search_with_vector_db(query, user_id, top_k)
            
            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            if include_context:
                user_context = await self._get_user_context(user_id)
            else:
                user_context = {}
            
            response_data = {
                "query": query,
                "user_id": user_id,
                "memories": memories,
                "user_context": user_context,
                "memory_type": memory_type,
                "count": len(memories)
            }
            
            if session_id:
                response_data["session_id"] = session_id
            
            return ToolResponse(
                success=True,
                data=response_data
            )
                
        except Exception as e:
            return ToolResponse(
                success=False,
                error=f"ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"
            )

    async def _search_with_mem0(self, query: str, user_id: str, top_k: int) -> List[Dict[str, Any]]:
        """Mem0ë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ê²€ìƒ‰ - ê³µì‹ ë¬¸ì„œì— ë”°ë¥¸ ì˜¬ë°”ë¥¸ ë°©ì‹"""
        try:
            # Mem0 ê²€ìƒ‰ ì‹¤í–‰
            search_result = self._memory.search(
                query=query,
                user_id=user_id,
                limit=top_k
            )
            
            memories = []
            for result in search_result:
                memory_entry = {
                    "content": result.get("content", ""),
                    "score": result.get("score", 0.0),
                    "timestamp": result.get("timestamp", ""),
                    "memory_type": "user",
                    "source": "mem0"
                }
                memories.append(memory_entry)
            
            return memories
            
        except Exception as e:
            print(f"âš ï¸  Mem0 ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    async def _search_with_vector_db(self, query: str, user_id: str, top_k: int) -> List[Dict[str, Any]]:
        """Vector DBë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ê²€ìƒ‰ (Fallback)"""
        try:
            # ì§ì ‘ Weaviate API í˜¸ì¶œ
            search_query = f"{query} user:{user_id}"
            
            response = requests.post(
                f"{self._weaviate_url}/v1/objects/{self._class_history}/search",
                json={
                    "query": search_query,
                    "limit": top_k
                },
                headers={"Content-Type": "application/json"},
                timeout=10,
            )
            
            memories = []
            if response.status_code == 200:
                results = response.json()
                
                for result in results:
                    memory_entry = {
                        "content": result.get("content", ""),
                        "score": result.get("score", 0.0),
                        "timestamp": result.get("timestamp", ""),
                        "memory_type": "vector_db",
                        "source": "weaviate"
                    }
                    memories.append(memory_entry)
            
            return memories
                
        except Exception as e:
            print(f"âš ï¸  Vector DB ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    async def _get_user_context(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¡°íšŒ"""
        try:
            # ì‚¬ìš©ìë³„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ êµ¬ì„±
            context = {
                "user_id": user_id,
                "preferences": {},
                "recent_interactions": [],
                "expertise_areas": [],
                "last_active": ""
            }
            
            # ìµœê·¼ ìƒí˜¸ì‘ìš© ê¸°ë¡ ì¡°íšŒ
            recent_query = f"user:{user_id}"
            response = requests.post(
                f"{self._weaviate_url}/v1/objects/{self._class_history}/search",
                json={
                    "query": recent_query,
                    "limit": 5
                },
                headers={"Content-Type": "application/json"},
                timeout=10,
            )
            
            if response.status_code == 200:
                recent_results = response.json()
                context["recent_interactions"] = [
                    {
                        "content": result.get("content", ""),
                        "timestamp": result.get("timestamp", "")
                    }
                    for result in recent_results
                ]
            
            return context
            
        except Exception as e:
            print(f"âš ï¸  ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"user_id": user_id}

    async def add_memory(self, user_id: str, messages: List[Dict[str, str]], metadata: Optional[Dict[str, Any]] = None) -> bool:
        """ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ì¶”ê°€ - ê³µì‹ ë¬¸ì„œì— ë”°ë¥¸ ì˜¬ë°”ë¥¸ ë°©ì‹"""
        try:
            if self._mem0_initialized and self._memory:
                # Mem0ì— ë©”ëª¨ë¦¬ ì¶”ê°€ (ê³µì‹ ë¬¸ì„œ ë°©ì‹)
                result = self._memory.add(
                    messages=messages,
                    user_id=user_id,
                    metadata=metadata or {}
                )
                return True
            else:
                # Weaviateì— ë©”ëª¨ë¦¬ ì¶”ê°€ (Fallback)
                content = "\n".join([msg.get("content", "") for msg in messages])
                response = requests.post(
                    f"{self._weaviate_url}/v1/objects",
                    json={
                        "class": self._class_history,
                        "properties": {
                            "title": f"Memory for {user_id}",
                            "content": content,
                            "metadata": f'{{"user_id": "{user_id}", "memory_type": "user", "timestamp": "2024-01-01T00:00:00Z"}}'
                        }
                    },
                    timeout=10,
                )
                return response.status_code in [200, 201]
                
        except Exception as e:
            print(f"âš ï¸  ë©”ëª¨ë¦¬ ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
            return False

    async def get_user_memory_summary(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë©”ëª¨ë¦¬ ìš”ì•½ ì¡°íšŒ - ê³µì‹ ë¬¸ì„œì— ë”°ë¥¸ ì˜¬ë°”ë¥¸ ë°©ì‹"""
        try:
            if self._mem0_initialized and self._memory:
                # Mem0ë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ìš”ì•½
                all_memories = self._memory.get_all(user_id=user_id)
                
                summary = {
                    "user_id": user_id,
                    "total_memories": len(all_memories),
                    "recent_memories": all_memories[-5:] if len(all_memories) > 5 else all_memories,
                    "memory_types": {},
                    "last_updated": all_memories[-1].get("timestamp", "") if all_memories else ""
                }
                
                return summary
            else:
                # Vector DBë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ìš”ì•½
                return await self._get_vector_db_summary(user_id)
                
        except Exception as e:
            print(f"âš ï¸  ë©”ëª¨ë¦¬ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"user_id": user_id, "error": str(e)}

    async def _get_vector_db_summary(self, user_id: str) -> Dict[str, Any]:
        """Vector DBë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ìš”ì•½"""
        try:
            response = requests.post(
                f"{self._weaviate_url}/v1/objects/{self._class_history}/search",
                json={
                    "query": f"user:{user_id}",
                    "limit": 10
                },
                headers={"Content-Type": "application/json"},
                timeout=10,
            )
            
            if response.status_code == 200:
                results = response.json()
                return {
                    "user_id": user_id,
                    "total_memories": len(results),
                    "recent_memories": results[-5:] if len(results) > 5 else results,
                    "memory_types": {"vector_db": len(results)},
                    "last_updated": results[-1].get("timestamp", "") if results else ""
                }
            else:
                return {"user_id": user_id, "error": "Vector DB ì¡°íšŒ ì‹¤íŒ¨"}
                
        except Exception as e:
            return {"user_id": user_id, "error": str(e)}

    def is_mem0_available(self) -> bool:
        """Mem0 ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self._mem0_initialized and self._memory is not None 