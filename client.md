# PRISM-Core í´ë¼ì´ì–¸íŠ¸ ê°€ì´ë“œ

PRISM-Coreë¥¼ ì´ìš©í•´ AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ê³  í™œìš©í•˜ëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ê¸°ë³¸ ì„¤ì •](#ê¸°ë³¸-ì„¤ì •)
2. [Vector DB í™œìš©](#vector-db-í™œìš©)
3. [LLM ì„œë¹„ìŠ¤ ì—°ë™](#llm-ì„œë¹„ìŠ¤-ì—°ë™)
4. [Tool ì‹œìŠ¤í…œ í™œìš©](#tool-ì‹œìŠ¤í…œ-í™œìš©)
5. [ì‹¤ì œ ì˜ˆì œ](#ì‹¤ì œ-ì˜ˆì œ)

## ğŸ”§ ê¸°ë³¸ ì„¤ì •

### 1. PRISM-Core ì„œë²„ ì‹œì‘

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/PRISM-System/prism-core.git
cd prism-core

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì—ì„œ í•„ìš”í•œ ì„¤ì • ìˆ˜ì •

# ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d
```

### 2. í´ë¼ì´ì–¸íŠ¸ í™˜ê²½ ì„¤ì •

```bash
# Python ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ë˜ëŠ” venv\Scripts\activate  # Windows

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install requests fastapi uvicorn
```

### 3. ì—°ê²° í…ŒìŠ¤íŠ¸

```python
import requests

# ì„œë²„ ìƒíƒœ í™•ì¸
response = requests.get("http://localhost:8000/")
print(response.json())
# ì˜ˆìƒ ì¶œë ¥: {"message": "Welcome to PRISM Core", "version": "0.1.0"}
```

## ğŸ§  Vector DB í™œìš©

### 1. ì¸ë±ìŠ¤ ìƒì„±

```python
import requests

def create_index(class_name: str, description: str = ""):
    """Vector DB ì¸ë±ìŠ¤ ìƒì„±"""
    url = "http://localhost:8000/api/vector-db/indices"
    data = {
        "class_name": class_name,
        "description": description,
        "vector_dimension": 384,
        "encoder_model": "sentence-transformers/all-MiniLM-L6-v2"
    }
    
    response = requests.post(url, json=data)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
create_index("Documents", "ë¬¸ì„œ ì €ì¥ì†Œ")
create_index("Knowledge", "ì§€ì‹ ë² ì´ìŠ¤")
```

### 2. ë¬¸ì„œ ì¶”ê°€

```python
def add_documents(class_name: str, documents: list):
    """ë¬¸ì„œë¥¼ Vector DBì— ì¶”ê°€"""
    url = f"http://localhost:8000/api/vector-db/documents/{class_name}/batch"
    
    response = requests.post(url, json=documents)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
documents = [
    {
        "title": "ë°˜ë„ì²´ ì œì¡° ê³µì •",
        "content": "ë°˜ë„ì²´ ì œì¡°ëŠ” ì›¨ì´í¼ ì¤€ë¹„ë¶€í„° íŒ¨í‚¤ì§•ê¹Œì§€ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì¹©ë‹ˆë‹¤.",
        "metadata": {"category": "manufacturing", "source": "manual"}
    },
    {
        "title": "í’ˆì§ˆ ê´€ë¦¬ ê°€ì´ë“œ",
        "content": "í’ˆì§ˆ ê´€ë¦¬ëŠ” ì œí’ˆì˜ ì¼ê´€ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë³´ì¥í•˜ëŠ” ì¤‘ìš”í•œ ê³¼ì •ì…ë‹ˆë‹¤.",
        "metadata": {"category": "quality", "source": "guide"}
    }
]

add_documents("Documents", documents)
```

### 3. ë¬¸ì„œ ê²€ìƒ‰

```python
def search_documents(query: str, class_name: str = "Documents", limit: int = 5):
    """ë¬¸ì„œ ê²€ìƒ‰"""
    url = f"http://localhost:8000/api/vector-db/search/{class_name}"
    data = {
        "query": query,
        "limit": limit
    }
    
    response = requests.post(url, json=data)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
results = search_documents("ë°˜ë„ì²´ ì œì¡° ê³µì •", "Documents", 3)
for result in results:
    print(f"ì ìˆ˜: {result['score']:.3f}")
    print(f"ë‚´ìš©: {result['content']}")
    print("---")
```

## ğŸ¤– LLM ì„œë¹„ìŠ¤ ì—°ë™

### 1. í…ìŠ¤íŠ¸ ìƒì„±

```python
def generate_text(prompt: str, model: str = "Qwen/Qwen3-0.6B"):
    """LLMì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ìƒì„±"""
    url = "http://localhost:8001/v1/chat/completions"
    data = {
        "model": model,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 500,
        "temperature": 0.7
    }
    
    response = requests.post(url, json=data)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
response = generate_text("ë°˜ë„ì²´ ì œì¡° ê³µì •ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
print(response['choices'][0]['message']['content'])
```

### 2. ëŒ€í™”í˜• ì±—ë´‡

```python
class ChatBot:
    def __init__(self, model: str = "Qwen/Qwen3-0.6B"):
        self.model = model
        self.conversation_history = []
        self.base_url = "http://localhost:8001/v1/chat/completions"
    
    def chat(self, message: str):
        """ëŒ€í™”í˜• ì‘ë‹µ ìƒì„±"""
        self.conversation_history.append({"role": "user", "content": message})
        
        data = {
            "model": self.model,
            "messages": self.conversation_history,
            "max_tokens": 300,
            "temperature": 0.7
        }
        
        response = requests.post(self.base_url, json=data)
        assistant_message = response.json()['choices'][0]['message']['content']
        
        self.conversation_history.append({"role": "assistant", "content": assistant_message})
        return assistant_message
    
    def reset(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []

# ì‚¬ìš© ì˜ˆì‹œ
bot = ChatBot()
response = bot.chat("ì•ˆë…•í•˜ì„¸ìš”!")
print(response)
```

## ğŸ”§ Tool ì‹œìŠ¤í…œ í™œìš©

PRISM-Coreì˜ Tool ì‹œìŠ¤í…œì€ AI ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” í•µì‹¬ êµ¬ì„± ìš”ì†Œì…ë‹ˆë‹¤. Toolì€ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ, API í˜¸ì¶œ, ê³„ì‚°, íŒŒì¼ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1. Toolì˜ ê°œë…ê³¼ ë™ì‘ì›ë¦¬

#### Toolì´ë€?
- **ì •ì˜**: AI ì—ì´ì „íŠ¸ê°€ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë‚˜ ì„œë¹„ìŠ¤
- **ëª©ì **: LLMì˜ í…ìŠ¤íŠ¸ ìƒì„± ëŠ¥ë ¥ì„ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ì—°ê²°
- **íŠ¹ì§•**: JSON ìŠ¤í‚¤ë§ˆë¡œ ì •ì˜ëœ ë§¤ê°œë³€ìˆ˜ë¥¼ ë°›ì•„ ê²°ê³¼ë¥¼ ë°˜í™˜

#### ë™ì‘ì›ë¦¬
```
1. ì‚¬ìš©ì ì§ˆì˜ â†’ 2. LLM ë¶„ì„ â†’ 3. Tool ì„ íƒ â†’ 4. Tool ì‹¤í–‰ â†’ 5. ê²°ê³¼ ë°˜í™˜
```

1. **ì‚¬ìš©ì ì§ˆì˜**: "A-1 ë¼ì¸ ì••ë ¥ ë°ì´í„°ë¥¼ ì¡°íšŒí•´ì¤˜"
2. **LLM ë¶„ì„**: ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒê°€ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨
3. **Tool ì„ íƒ**: `database_query` Tool ì„ íƒ
4. **Tool ì‹¤í–‰**: SQL ì¿¼ë¦¬ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì¡°íšŒ
5. **ê²°ê³¼ ë°˜í™˜**: ì¡°íšŒëœ ë°ì´í„°ë¥¼ í¬í•¨í•œ ì‘ë‹µ ìƒì„±

### 2. Tool ì •ì˜ ë° ìŠ¤í‚¤ë§ˆ

#### ê¸°ë³¸ Tool êµ¬ì¡°
```python
class CustomTool:
    def __init__(self):
        self.name = "tool_name"
        self.description = "ë„êµ¬ ì„¤ëª…"
        self.parameters_schema = {
            "type": "object",
            "properties": {
                "parameter1": {
                    "type": "string",
                    "description": "ë§¤ê°œë³€ìˆ˜ ì„¤ëª…"
                }
            },
            "required": ["parameter1"]
        }
    
    async def execute(self, parameters: dict):
        # ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
        return {"result": "ì‘ì—… ê²°ê³¼"}
```

#### ë§¤ê°œë³€ìˆ˜ ìŠ¤í‚¤ë§ˆ ìƒì„¸ ì„¤ëª…
```python
parameters_schema = {
    "type": "object",                    # ê°ì²´ íƒ€ì…
    "properties": {                      # ì†ì„± ì •ì˜
        "query": {
            "type": "string",            # ë¬¸ìì—´ íƒ€ì…
            "description": "SQL ì¿¼ë¦¬",   # ì„¤ëª…
            "enum": ["SELECT", "INSERT"] # ì—´ê±°í˜• (ì„ íƒì‚¬í•­)
        },
        "limit": {
            "type": "integer",           # ì •ìˆ˜ íƒ€ì…
            "description": "ë°˜í™˜í•  í–‰ ìˆ˜",
            "minimum": 1,                # ìµœì†Œê°’
            "maximum": 1000              # ìµœëŒ€ê°’
        },
        "filters": {
            "type": "object",            # ê°ì²´ íƒ€ì…
            "description": "í•„í„° ì¡°ê±´",
            "properties": {
                "line": {"type": "string"},
                "date_from": {"type": "string", "format": "date"}
            }
        }
    },
    "required": ["query"]               # í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜
}
```

### 3. Tool ë“±ë¡ ë° ê´€ë¦¬

#### 3.1 Tool ë“±ë¡
```python
def register_tool(tool_config: dict):
    """ìƒˆë¡œìš´ Tool ë“±ë¡"""
    url = "http://localhost:8000/api/tools/register"
    
    response = requests.post(url, json=tool_config)
    return response.json()

# ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ Tool ë“±ë¡
database_tool = {
    "name": "database_query",
    "description": "PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
    "parameters_schema": {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "ì‹¤í–‰í•  SQL ì¿¼ë¦¬"
            },
            "timeout": {
                "type": "integer",
                "description": "ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ (ì´ˆ)",
                "default": 30
            }
        },
        "required": ["query"]
    },
    "tool_type": "database"
}

result = register_tool(database_tool)
print(f"Tool ë“±ë¡ ê²°ê³¼: {result}")
```

#### 3.2 Tool ëª©ë¡ ì¡°íšŒ
```python
def list_tools():
    """ë“±ë¡ëœ Tool ëª©ë¡ ì¡°íšŒ"""
    url = "http://localhost:8000/api/tools"
    
    response = requests.get(url)
    tools = response.json()
    
    print("ë“±ë¡ëœ Tools:")
    for tool in tools:
        print(f"- {tool['name']}: {tool['description']}")
        print(f"  ë§¤ê°œë³€ìˆ˜: {tool['parameters_schema']}")
    
    return tools

tools = list_tools()
```

#### 3.3 Tool ì •ë³´ ì¡°íšŒ
```python
def get_tool_info(tool_name: str):
    """íŠ¹ì • Toolì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    url = f"http://localhost:8000/api/tools/{tool_name}"
    
    response = requests.get(url)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
tool_info = get_tool_info("database_query")
print(f"Tool ì •ë³´: {tool_info}")
```

#### 3.4 Tool ì‚­ì œ
```python
def delete_tool(tool_name: str):
    """Tool ì‚­ì œ"""
    url = f"http://localhost:8000/api/tools/{tool_name}"
    
    response = requests.delete(url)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
result = delete_tool("unused_tool")
print(f"ì‚­ì œ ê²°ê³¼: {result}")
```

### 4. Tool ì‹¤í–‰ ë° í™œìš©

#### 4.1 ì§ì ‘ Tool ì‹¤í–‰
```python
def execute_tool(tool_name: str, parameters: dict):
    """Tool ì§ì ‘ ì‹¤í–‰"""
    url = "http://localhost:8000/api/tools/execute"
    data = {
        "tool_name": tool_name,
        "parameters": parameters
    }
    
    response = requests.post(url, json=data)
    return response.json()

# ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì˜ˆì‹œ
result = execute_tool("database_query", {
    "query": "SELECT * FROM pressure_sensors WHERE line='A-1' LIMIT 10"
})

if result["success"]:
    print("ì¡°íšŒëœ ë°ì´í„°:")
    for row in result["result"]["rows"]:
        print(f"- {row}")
else:
    print(f"ì˜¤ë¥˜: {result['error_message']}")
```

#### 4.2 ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ Tool ì‚¬ìš©

##### Agentì— Tool ë“±ë¡ì˜ ì˜ë¯¸

ì—ì´ì „íŠ¸ì— Toolì„ ë“±ë¡í•˜ëŠ” ê²ƒì€ **AI ì—ì´ì „íŠ¸ê°€ ìë™ìœ¼ë¡œ Toolì„ ì„ íƒí•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê¶Œí•œì„ ë¶€ì—¬**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

```python
def assign_tools_to_agent(agent_name: str, tool_names: list):
    """ì—ì´ì „íŠ¸ì— Tool í• ë‹¹"""
    url = f"http://localhost:8000/api/agents/{agent_name}/tools"
    
    data = {
        "agent_name": agent_name,
        "tool_names": tool_names
    }
    
    response = requests.post(url, json=data)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ: ë¶„ì„ ì—ì´ì „íŠ¸ì— ë„êµ¬ í• ë‹¹
result = assign_tools_to_agent("analysis_agent", [
    "database_query",      # ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
    "vector_search",       # ë²¡í„° ê²€ìƒ‰
    "statistical_analysis" # í†µê³„ ë¶„ì„
])
print(f"Tool í• ë‹¹ ê²°ê³¼: {result}")
```

**Agent ë“±ë¡ì˜ ì˜ë¯¸:**
- **ê¶Œí•œ ë¶€ì—¬**: ì—ì´ì „íŠ¸ê°€ íŠ¹ì • Toolì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¶Œí•œ
- **ì»¨í…ìŠ¤íŠ¸ ì œê³µ**: LLMì—ê²Œ "ì´ ì—ì´ì „íŠ¸ëŠ” ì–´ë–¤ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€" ì•Œë ¤ì¤Œ
- **ìë™ ì„ íƒ**: ì‚¬ìš©ì ì§ˆì˜ì— ë”°ë¼ LLMì´ ì ì ˆí•œ Toolì„ ìë™ìœ¼ë¡œ ì„ íƒ
- **ë³´ì•ˆ**: ì—ì´ì „íŠ¸ë³„ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ Toolì„ ì œí•œí•˜ì—¬ ë³´ì•ˆ ê°•í™”

##### Tool íŠ¸ë¦¬ê±° ì‹œ ì‹¤ì œ ë™ì‘ ê³¼ì •

Toolì´ íŠ¸ë¦¬ê±°ë  ë•Œì˜ ì „ì²´ ë™ì‘ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤:

```python
def invoke_agent_with_tools(agent_name: str, prompt: str):
    """ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ Tool ìë™ ì‚¬ìš©"""
    url = f"http://localhost:8000/api/agents/{agent_name}/invoke"
    
    data = {
        "prompt": prompt,
        "use_tools": True,           # Tool ì‚¬ìš© í™œì„±í™”
        "max_tool_calls": 5,         # ìµœëŒ€ Tool í˜¸ì¶œ íšŸìˆ˜
        "max_tokens": 1000,
        "temperature": 0.3
    }
    
    response = requests.post(url, json=data)
    return response.json()

# ì‚¬ìš© ì˜ˆì‹œ
result = invoke_agent_with_tools("analysis_agent", 
    "A-1 ë¼ì¸ ì••ë ¥ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ì´ìƒì¹˜ë¥¼ ë¶„ì„í•´ì¤˜")

print(f"ì—ì´ì „íŠ¸ ì‘ë‹µ: {result['text']}")
print(f"ì‚¬ìš©ëœ Tools: {result['tools_used']}")
print(f"Tool ê²°ê³¼: {result['tool_results']}")
```

**ì‹¤ì œ ë™ì‘ ê³¼ì •:**

```
1. í´ë¼ì´ì–¸íŠ¸ ìš”ì²­
   â†“
2. ì„œë²„ì—ì„œ ì—ì´ì „íŠ¸ ë¡œë“œ
   â†“
3. LLMì´ ì‚¬ìš©ì ì§ˆì˜ ë¶„ì„
   â†“
4. Tool ì„ íƒ ë° í˜¸ì¶œ
   â†“
5. Tool ì‹¤í–‰
   â†“
6. ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬
   â†“
7. ìµœì¢… ì‘ë‹µ ìƒì„±
   â†“
8. í´ë¼ì´ì–¸íŠ¸ì— ì‘ë‹µ
```

**ìƒì„¸ ë™ì‘ ê³¼ì •:**

1. **í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ë‹¨ê³„**
   ```python
   # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì—ì´ì „íŠ¸ í˜¸ì¶œ
   response = requests.post(
       "http://localhost:8000/api/agents/analysis_agent/invoke",
       json={
           "prompt": "A-1 ë¼ì¸ ì••ë ¥ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ì´ìƒì¹˜ë¥¼ ë¶„ì„í•´ì¤˜",
           "use_tools": True,
           "max_tool_calls": 5
       }
   )
   ```

2. **ì„œë²„ì—ì„œ ì—ì´ì „íŠ¸ ë¡œë“œ**
   ```python
   # ì„œë²„ ë‚´ë¶€ ë™ì‘ (PrismLLMService)
   agent = agent_registry.get_agent("analysis_agent")
   # agent.tools = ["database_query", "vector_search", "statistical_analysis"]
   ```

3. **LLMì´ ì‚¬ìš©ì ì§ˆì˜ ë¶„ì„**
   ```python
   # LLMì´ ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ Tool ê²°ì •
   # "A-1 ë¼ì¸ ì••ë ¥ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ì´ìƒì¹˜ë¥¼ ë¶„ì„í•´ì¤˜"
   # â†’ database_query (ë°ì´í„° ì¡°íšŒ) + statistical_analysis (ì´ìƒì¹˜ ë¶„ì„) í•„ìš”
   ```

4. **Tool ì„ íƒ ë° í˜¸ì¶œ**
   ```python
   # LLMì´ ìë™ìœ¼ë¡œ Tool í˜¸ì¶œ ê²°ì •
   tool_calls = [
       {
           "tool": "database_query",
           "parameters": {
               "query": "SELECT * FROM pressure_sensors WHERE line='A-1'"
           }
       }
   ]
   ```

5. **Tool ì‹¤í–‰**
   ```python
   # ì„œë²„ì—ì„œ Tool ì‹¤í–‰
   tool_result = tool_registry.execute_tool("database_query", {
       "query": "SELECT * FROM pressure_sensors WHERE line='A-1'"
   })
   # ê²°ê³¼: {"rows": [{"id": 1, "pressure": 2.5, ...}]}
   ```

6. **ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬**
   ```python
   # Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ LLMì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
   context = f"""
   Tool ì‹¤í–‰ ê²°ê³¼:
   database_query: {tool_result}
   
   ì´ì œ ì´ìƒì¹˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
   """
   ```

7. **ìµœì¢… ì‘ë‹µ ìƒì„±**
   ```python
   # LLMì´ Tool ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±
   final_response = llm.generate(context + "ì‚¬ìš©ì ì§ˆì˜: " + prompt)
   ```

8. **í´ë¼ì´ì–¸íŠ¸ì— ì‘ë‹µ**
   ```python
   # í´ë¼ì´ì–¸íŠ¸ì— ìµœì¢… ê²°ê³¼ ë°˜í™˜
   return {
       "text": "A-1 ë¼ì¸ ì••ë ¥ ë°ì´í„° ë¶„ì„ ê²°ê³¼...",
       "tools_used": ["database_query", "statistical_analysis"],
       "tool_results": [
           {
               "tool": "database_query",
               "result": {"rows": [...]}
           },
           {
               "tool": "statistical_analysis", 
               "result": {"anomalies": [...]}
           }
       ]
   }
   ```

##### Tool íŠ¸ë¦¬ê±° ì‹œ ì„œë²„-í´ë¼ì´ì–¸íŠ¸ í†µì‹  íë¦„

```python
# ì „ì²´ í†µì‹  íë¦„ ì˜ˆì‹œ
def demonstrate_tool_workflow():
    """Tool ì›Œí¬í”Œë¡œìš° ì‹œì—°"""
    
    # 1. ì—ì´ì „íŠ¸ ë“±ë¡ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
    agent_config = {
        "name": "data_analyst",
        "description": "ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€",
        "role_prompt": "ë‹¹ì‹ ì€ ì œì¡° ê³µì • ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
        "tools": []  # ì´ˆê¸°ì—ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸
    }
    
    # ì—ì´ì „íŠ¸ ë“±ë¡
    requests.post("http://localhost:8000/api/agents", json=agent_config)
    
    # 2. Tool í• ë‹¹
    assign_tools_to_agent("data_analyst", [
        "database_query",
        "vector_search", 
        "statistical_analysis"
    ])
    
    # 3. ì—ì´ì „íŠ¸ í˜¸ì¶œ (Tool ìë™ ì‚¬ìš©)
    result = invoke_agent_with_tools("data_analyst",
        "A-1 ë¼ì¸ì—ì„œ ì••ë ¥ ì´ìƒì´ ë°œìƒí•œ ê²ƒ ê°™ì•„. ìµœê·¼ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ë¶„ì„í•´ì¤˜.")
    
    print("=== Tool ì›Œí¬í”Œë¡œìš° ê²°ê³¼ ===")
    print(f"ìµœì¢… ì‘ë‹µ: {result['text']}")
    print(f"ì‚¬ìš©ëœ Tools: {result['tools_used']}")
    print(f"Tool ì‹¤í–‰ íšŸìˆ˜: {len(result['tool_results'])}")
    
    # 4. Tool ì‹¤í–‰ ê²°ê³¼ ìƒì„¸ í™•ì¸
    for i, tool_result in enumerate(result['tool_results'], 1):
        print(f"\nTool {i}: {tool_result['tool']}")
        print(f"ê²°ê³¼: {tool_result['result']}")

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
demonstrate_tool_workflow()
```

##### Tool ì‚¬ìš© ê¶Œí•œ ê´€ë¦¬

```python
def manage_tool_permissions():
    """Tool ì‚¬ìš© ê¶Œí•œ ê´€ë¦¬"""
    
    # 1. ì—ì´ì „íŠ¸ë³„ Tool ê¶Œí•œ ì„¤ì •
    agent_tools = {
        "data_analyst": ["database_query", "statistical_analysis", "vector_search"],
        "system_monitor": ["database_query", "alert_system"],
        "report_generator": ["database_query", "file_writer", "email_sender"]
    }
    
    # 2. ê¶Œí•œ í• ë‹¹
    for agent_name, tools in agent_tools.items():
        assign_tools_to_agent(agent_name, tools)
        print(f"{agent_name}ì— {len(tools)}ê°œ Tool í• ë‹¹ ì™„ë£Œ")
    
    # 3. ê¶Œí•œ í™•ì¸
    for agent_name in agent_tools.keys():
        agent_info = requests.get(f"http://localhost:8000/api/agents/{agent_name}").json()
        print(f"{agent_name} ì‚¬ìš© ê°€ëŠ¥ Tool: {agent_info['tools']}")

# ê¶Œí•œ ê´€ë¦¬ ì‹¤í–‰
manage_tool_permissions()
```

### 5. ê³ ê¸‰ Tool ê°œë°œ

#### 5.1 ë³µì¡í•œ Tool ì˜ˆì‹œ
```python
class AdvancedAnalysisTool:
    def __init__(self):
        self.name = "advanced_analysis"
        self.description = "ë³µí•©ì ì¸ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤"
        self.parameters_schema = {
            "type": "object",
            "properties": {
                "analysis_type": {
                    "type": "string",
                    "enum": ["trend", "anomaly", "correlation"],
                    "description": "ë¶„ì„ ìœ í˜•"
                },
                "data_source": {
                    "type": "string",
                    "description": "ë°ì´í„° ì†ŒìŠ¤ (í…Œì´ë¸”ëª…)"
                },
                "time_range": {
                    "type": "object",
                    "properties": {
                        "start": {"type": "string", "format": "date-time"},
                        "end": {"type": "string", "format": "date-time"}
                    },
                    "required": ["start", "end"]
                },
                "parameters": {
                    "type": "object",
                    "description": "ë¶„ì„ë³„ ì¶”ê°€ ë§¤ê°œë³€ìˆ˜"
                }
            },
            "required": ["analysis_type", "data_source"]
        }
    
    async def execute(self, parameters: dict):
        analysis_type = parameters["analysis_type"]
        data_source = parameters["data_source"]
        time_range = parameters.get("time_range")
        
        if analysis_type == "trend":
            return await self._analyze_trend(data_source, time_range)
        elif analysis_type == "anomaly":
            return await self._detect_anomaly(data_source, time_range)
        elif analysis_type == "correlation":
            return await self._analyze_correlation(data_source, time_range)
    
    async def _analyze_trend(self, data_source, time_range):
        # íŠ¸ë Œë“œ ë¶„ì„ ë¡œì§
        return {
            "trend": "increasing",
            "slope": 0.15,
            "confidence": 0.85
        }
    
    async def _detect_anomaly(self, data_source, time_range):
        # ì´ìƒì¹˜ íƒì§€ ë¡œì§
        return {
            "anomalies": [
                {"timestamp": "2025-08-22T10:30:00Z", "value": 3.2, "severity": "high"}
            ],
            "total_anomalies": 1
        }
    
    async def _analyze_correlation(self, data_source, time_range):
        # ìƒê´€ê´€ê³„ ë¶„ì„ ë¡œì§
        return {
            "correlation_matrix": {
                "pressure_temperature": 0.75,
                "pressure_flow": 0.45
            }
        }
```

#### 5.2 Tool ì²´ì´ë‹ (Tool Chaining)
```python
def create_tool_chain():
    """ì—¬ëŸ¬ Toolì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì²´ì¸ ìƒì„±"""
    
    # 1ë‹¨ê³„: ë°ì´í„° ì¡°íšŒ
    data_result = execute_tool("database_query", {
        "query": "SELECT * FROM sensors WHERE timestamp > '2025-08-22'"
    })
    
    if not data_result["success"]:
        return {"error": "ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨"}
    
    # 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬
    preprocess_result = execute_tool("data_preprocessor", {
        "data": data_result["result"]["rows"],
        "operations": ["normalize", "remove_outliers"]
    })
    
    if not preprocess_result["success"]:
        return {"error": "ì „ì²˜ë¦¬ ì‹¤íŒ¨"}
    
    # 3ë‹¨ê³„: ë¶„ì„ ìˆ˜í–‰
    analysis_result = execute_tool("statistical_analysis", {
        "data": preprocess_result["result"]["processed_data"],
        "methods": ["mean", "std", "correlation"]
    })
    
    return {
        "data_count": len(data_result["result"]["rows"]),
        "preprocessing_status": preprocess_result["result"]["status"],
        "analysis_results": analysis_result["result"]
    }

# ì‚¬ìš© ì˜ˆì‹œ
chain_result = create_tool_chain()
print(f"Tool ì²´ì¸ ê²°ê³¼: {chain_result}")
```

### 6. Tool ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

#### 6.1 Tool ì‹¤í–‰ ë¡œê·¸
```python
def monitor_tool_execution(tool_name: str, parameters: dict):
    """Tool ì‹¤í–‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì„±ëŠ¥ ì¸¡ì •"""
    import time
    
    start_time = time.time()
    
    # Tool ì‹¤í–‰
    result = execute_tool(tool_name, parameters)
    
    execution_time = time.time() - start_time
    
    # ì‹¤í–‰ ì •ë³´ ë¡œê¹…
    log_info = {
        "tool_name": tool_name,
        "parameters": parameters,
        "execution_time": execution_time,
        "success": result["success"],
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    
    print(f"Tool ì‹¤í–‰ ë¡œê·¸: {log_info}")
    return result

# ì‚¬ìš© ì˜ˆì‹œ
result = monitor_tool_execution("database_query", {
    "query": "SELECT COUNT(*) FROM sensors"
})
```

#### 6.2 Tool ì˜¤ë¥˜ ì²˜ë¦¬
```python
def safe_tool_execution(tool_name: str, parameters: dict, max_retries: int = 3):
    """ì•ˆì „í•œ Tool ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    
    for attempt in range(max_retries):
        try:
            result = execute_tool(tool_name, parameters)
            
            if result["success"]:
                return result
            
            print(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {result.get('error_message', 'Unknown error')}")
            
        except Exception as e:
            print(f"ì‹œë„ {attempt + 1} ì˜ˆì™¸: {str(e)}")
        
        if attempt < max_retries - 1:
            import time
            time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
    
    return {
        "success": False,
        "error_message": f"Tool ì‹¤í–‰ ì‹¤íŒ¨ (ìµœëŒ€ {max_retries}íšŒ ì‹œë„)"
    }

# ì‚¬ìš© ì˜ˆì‹œ
result = safe_tool_execution("database_query", {
    "query": "SELECT * FROM sensors"
})
```

### 7. Tool í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

#### 7.1 Tool ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
def test_tool_functionality():
    """Tool ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            "name": "ê¸°ë³¸ ë°ì´í„° ì¡°íšŒ",
            "tool": "database_query",
            "parameters": {"query": "SELECT 1 as test"},
            "expected": {"success": True}
        },
        {
            "name": "ì˜ëª»ëœ ì¿¼ë¦¬",
            "tool": "database_query", 
            "parameters": {"query": "INVALID SQL"},
            "expected": {"success": False}
        }
    ]
    
    results = []
    for test_case in test_cases:
        result = execute_tool(test_case["tool"], test_case["parameters"])
        
        test_result = {
            "test_name": test_case["name"],
            "expected": test_case["expected"]["success"],
            "actual": result["success"],
            "passed": result["success"] == test_case["expected"]["success"]
        }
        
        results.append(test_result)
        print(f"í…ŒìŠ¤íŠ¸ '{test_case['name']}': {'í†µê³¼' if test_result['passed'] else 'ì‹¤íŒ¨'}")
    
    return results

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
test_results = test_tool_functionality()
```

ì´ì œ Tool ì‹œìŠ¤í…œì˜ ì „ì²´ ë™ì‘ ê³¼ì •ì„ ì™„ì „íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€ 

## ğŸ¤– ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ìƒì„± ê°€ì´ë“œ

PRISM-Coreë¥¼ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“œëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œì…ë‹ˆë‹¤.

### 1. ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

```python
# ì˜ˆì‹œ: Manufacturing Performance Analysis Agent (MPA Agent)
class ManufacturingPerformanceAgent:
    """
    ì œì¡° ì„±ëŠ¥ ë¶„ì„ ì—ì´ì „íŠ¸
    
    ê¸°ëŠ¥:
    - DBì—ì„œ íŠ¹ì • êµ¬ê°„ ë°ì´í„° ì¡°íšŒ
    - ë³´ìœ  ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ ì¸¡ì •
    - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë¯¸ë˜ ì˜ˆì¸¡
    - ì´ìƒ ë°œìƒ ê°€ëŠ¥ì„± ë†’ì€ êµ¬ê°„ ë¶„ì„
    - Compliance ê²€ì¦
    """
    
    def __init__(self, agent_name: str = "mpa_agent"):
        self.agent_name = agent_name
        self.agent_manager = None
        self.workflow_manager = None
        self.tool_registry = None
        self.llm_service = None
        
    def initialize_agent(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        pass
        
    def setup_tools(self):
        """ì—ì´ì „íŠ¸ ì „ìš© ë„êµ¬ ì„¤ì •"""
        pass
        
    def register_workflows(self):
        """ì›Œí¬í”Œë¡œìš° ë“±ë¡"""
        pass
```

### 2. ì—ì´ì „íŠ¸ë³„ ì„¤ì • íŒŒì¼ êµ¬ì¡°

```bash
# mpa-agent/
â”œâ”€â”€ .env-local                    # ì—ì´ì „íŠ¸ ì „ìš© í™˜ê²½ ì„¤ì •
â”œâ”€â”€ docker-compose.yml           # ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ êµ¬ì„±
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # ì—ì´ì „íŠ¸ ë©”ì¸ ì§„ì…ì 
â”‚   â”œâ”€â”€ config.py                # ì„¤ì • ê´€ë¦¬
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ mpa_agent.py         # ë©”ì¸ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ data_analyzer.py     # ë°ì´í„° ë¶„ì„ ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ model_evaluator.py   # ëª¨ë¸ í‰ê°€ ëª¨ë“ˆ
â”‚   â”‚   â””â”€â”€ predictor.py         # ì˜ˆì¸¡ ëª¨ë“ˆ
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ mpa_tool_setup.py    # MPA ì „ìš© ë„êµ¬ ì„¤ì •
â”‚       â”œâ”€â”€ data_query_tool.py   # ë°ì´í„° ì¡°íšŒ ë„êµ¬
â”‚       â”œâ”€â”€ model_performance_tool.py  # ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ë„êµ¬
â”‚       â””â”€â”€ prediction_tool.py   # ì˜ˆì¸¡ ë„êµ¬
â”œâ”€â”€ data/                        # ë°ì´í„° ì €ì¥ì†Œ
â”œâ”€â”€ models/                      # ëª¨ë¸ ì €ì¥ì†Œ
â””â”€â”€ logs/                        # ë¡œê·¸ ì €ì¥ì†Œ
```

### 3. í™˜ê²½ ì„¤ì • (.env-local)

```bash
# MPA Agent Server Configuration
APP_BASE_URL=http://localhost:8200
APP_HOST=0.0.0.0
APP_PORT=8200
RELOAD=true

# vLLM Configuration
OPENAI_BASE_URL=http://localhost:8001/v1
VLLM_MODEL=Qwen/Qwen3-14B
OPENAI_API_KEY=EMPTY

# PRISM-Core API Configuration
PRISM_CORE_BASE_URL=http://localhost:8000

# Vector DB Configuration (MPA-specific instance)
WEAVIATE_URL=http://localhost:18081
WEAVIATE_API_KEY=

# Vector Encoder Configuration
VECTOR_ENCODER_MODEL=sentence-transformers/all-MiniLM-L6-v2
VECTOR_DIM=384

# Database Configuration (Manufacturing DB)
MANUFACTURING_DB_URL=postgresql://user:pass@localhost:5432/manufacturing_db

# Model Configuration
MODEL_STORAGE_PATH=/app/models
PERFORMANCE_THRESHOLD=0.85
PREDICTION_HORIZON=24  # hours
```

### 4. ë©”ì¸ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ (ìˆ˜ë„ ì½”ë“œ)

```python
from prism_core.core.agents import AgentManager, WorkflowManager
from prism_core.core.tools import ToolRegistry
from prism_core.core.llm import PrismLLMService

class ManufacturingPerformanceAgent:
    """
    ì œì¡° ì„±ëŠ¥ ë¶„ì„ ì—ì´ì „íŠ¸ - ìˆ˜ë„ ì½”ë“œ
    """
    
    def __init__(self):
        # 1. ê¸°ë³¸ ì„¤ì • ë¡œë“œ
        self.load_configuration()
        
        # 2. ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.initialize_managers()
        
        # 3. ë„êµ¬ ì„¤ì •
        self.setup_agent_tools()
        
        # 4. ì›Œí¬í”Œë¡œìš° ë“±ë¡
        self.register_workflows()
        
        # 5. LLM ì„œë¹„ìŠ¤ ì—°ê²°
        self.connect_llm_service()
    
    def load_configuration(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        # .env-localì—ì„œ ì„¤ì • ë¡œë“œ
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´
        # ëª¨ë¸ ì €ì¥ì†Œ ê²½ë¡œ
        # ì„±ëŠ¥ ì„ê³„ê°’ ë“±
    
    def initialize_managers(self):
        """ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        # AgentManager ìƒì„±
        # WorkflowManager ìƒì„±
        # ToolRegistry ìƒì„±
    
    def setup_agent_tools(self):
        """ì—ì´ì „íŠ¸ ì „ìš© ë„êµ¬ ì„¤ì •"""
        # 1. ë°ì´í„° ì¡°íšŒ ë„êµ¬ (DataQueryTool)
        # 2. ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ë„êµ¬ (ModelPerformanceTool)
        # 3. ì˜ˆì¸¡ ë„êµ¬ (PredictionTool)
        # 4. ì´ìƒ íƒì§€ ë„êµ¬ (AnomalyDetectionTool)
        # 5. Compliance ê²€ì¦ ë„êµ¬ (ComplianceTool)
    
    def register_workflows(self):
        """ì›Œí¬í”Œë¡œìš° ë“±ë¡"""
        # 1. ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°
        # 2. ëª¨ë¸ í‰ê°€ ì›Œí¬í”Œë¡œìš°
        # 3. ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš°
        # 4. ì´ìƒ íƒì§€ ì›Œí¬í”Œë¡œìš°
        # 5. Compliance ê²€ì¦ ì›Œí¬í”Œë¡œìš°
    
    # === í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë©”ì„œë“œë“¤ ===
    
    def analyze_manufacturing_performance(self, time_range: dict, equipment_ids: list):
        """
        ì œì¡° ì„±ëŠ¥ ë¶„ì„ ë©”ì¸ ì›Œí¬í”Œë¡œìš°
        """
        # 1. ë°ì´í„° ì¡°íšŒ
        data = self.query_manufacturing_data(time_range, equipment_ids)
        
        # 2. ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •
        model_performance = self.evaluate_model_performance(data)
        
        # 3. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        best_model = self.select_best_model(model_performance)
        
        # 4. ë¯¸ë˜ ì˜ˆì¸¡
        predictions = self.predict_future_performance(best_model, data)
        
        # 5. ì´ìƒ íƒì§€
        anomalies = self.detect_anomalies(predictions, data)
        
        # 6. Compliance ê²€ì¦
        compliance_report = self.verify_compliance(anomalies, predictions)
        
        return {
            "data": data,
            "model_performance": model_performance,
            "best_model": best_model,
            "predictions": predictions,
            "anomalies": anomalies,
            "compliance_report": compliance_report
        }
    
    def query_manufacturing_data(self, time_range: dict, equipment_ids: list):
        """ì œì¡° ë°ì´í„° ì¡°íšŒ"""
        # 1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì„¼ì„œ ë°ì´í„° ì¡°íšŒ
        # 2. ì„¤ë¹„ ìƒíƒœ ë°ì´í„° ì¡°íšŒ
        # 3. í’ˆì§ˆ ì¸¡ì • ë°ì´í„° ì¡°íšŒ
        # 4. í™˜ê²½ ë°ì´í„° ì¡°íšŒ
        # 5. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ê·œí™”
    
    def evaluate_model_performance(self, data: dict):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        # 1. ë³´ìœ  ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        # 2. ê° ëª¨ë¸ì— ëŒ€í•´ ì„±ëŠ¥ ì¸¡ì •
        # 3. ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ê³„ì‚°
        # 4. êµì°¨ ê²€ì¦ ìˆ˜í–‰
        # 5. ì„±ëŠ¥ ì ìˆ˜ ì •ë ¬
    
    def select_best_model(self, model_performance: dict):
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ"""
        # 1. ì„±ëŠ¥ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        # 2. ì„ê³„ê°’ ì´ìƒ ëª¨ë¸ í•„í„°ë§
        # 3. ì•ˆì •ì„± ì ìˆ˜ ê³ ë ¤
        # 4. ìµœì¢… ëª¨ë¸ ì„ íƒ
    
    def predict_future_performance(self, model: dict, data: dict):
        """ë¯¸ë˜ ì„±ëŠ¥ ì˜ˆì¸¡"""
        # 1. ëª¨ë¸ ë¡œë“œ
        # 2. ì˜ˆì¸¡ ê¸°ê°„ ì„¤ì •
        # 3. ì…ë ¥ ë°ì´í„° ì¤€ë¹„
        # 4. ì˜ˆì¸¡ ì‹¤í–‰
        # 5. ì˜ˆì¸¡ ê²°ê³¼ í›„ì²˜ë¦¬
    
    def detect_anomalies(self, predictions: dict, historical_data: dict):
        """ì´ìƒ íƒì§€"""
        # 1. ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ë¹„êµ
        # 2. í†µê³„ì  ì´ìƒ íƒì§€
        # 3. ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì´ìƒ íƒì§€
        # 4. ì´ìƒ êµ¬ê°„ ì‹ë³„
        # 5. ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
    
    def verify_compliance(self, anomalies: dict, predictions: dict):
        """Compliance ê²€ì¦"""
        # 1. ê·œì • ì¤€ìˆ˜ ê¸°ì¤€ ë¡œë“œ
        # 2. ì˜ˆì¸¡ ê²°ê³¼ ê²€ì¦
        # 3. ì´ìƒ êµ¬ê°„ ê·œì • ì¤€ìˆ˜ í™•ì¸
        # 4. ìœ„í—˜ë„ í‰ê°€
        # 5. ê¶Œì¥ì‚¬í•­ ìƒì„±
    
    # === ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë©”ì„œë“œë“¤ ===
    
    def execute_data_analysis_workflow(self, parameters: dict):
        """ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        # 1. ì›Œí¬í”Œë¡œìš° ì •ì˜
        # 2. ë‹¨ê³„ë³„ ì‹¤í–‰
        # 3. ê²°ê³¼ ìˆ˜ì§‘
        # 4. ì˜¤ë¥˜ ì²˜ë¦¬
    
    def execute_model_evaluation_workflow(self, parameters: dict):
        """ëª¨ë¸ í‰ê°€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        # 1. ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        # 2. ì„±ëŠ¥ ì¸¡ì •
        # 3. ê²°ê³¼ ë¹„êµ
        # 4. ìµœì  ëª¨ë¸ ì„ íƒ
    
    def execute_prediction_workflow(self, parameters: dict):
        """ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        # 1. ëª¨ë¸ ë¡œë“œ
        # 2. ë°ì´í„° ì „ì²˜ë¦¬
        # 3. ì˜ˆì¸¡ ì‹¤í–‰
        # 4. ê²°ê³¼ ê²€ì¦
    
    def execute_anomaly_detection_workflow(self, parameters: dict):
        """ì´ìƒ íƒì§€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        # 1. ë°ì´í„° ë¶„ì„
        # 2. ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
        # 3. ê²°ê³¼ í•„í„°ë§
        # 4. ìœ„í—˜ë„ í‰ê°€
    
    def execute_compliance_verification_workflow(self, parameters: dict):
        """Compliance ê²€ì¦ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        # 1. ê·œì • ê¸°ì¤€ ë¡œë“œ
        # 2. ë°ì´í„° ê²€ì¦
        # 3. ê·œì • ì¤€ìˆ˜ í™•ì¸
        # 4. ë³´ê³ ì„œ ìƒì„±
```

### 5. ë„êµ¬ ì„¤ì • í´ë˜ìŠ¤ (ìˆ˜ë„ ì½”ë“œ)

```python
from prism_core.core.tools import (
    create_rag_search_tool,
    create_compliance_tool,
    create_memory_search_tool,
    ToolRegistry
)

class MPAToolSetup:
    """
    MPA Agent ì „ìš© ë„êµ¬ ì„¤ì • í´ë˜ìŠ¤
    """
    
    def __init__(self):
        # MPA ì „ìš© ì„¤ì •
        self.weaviate_url = settings.WEAVIATE_URL
        self.openai_base_url = settings.OPENAI_BASE_URL
        self.openai_api_key = settings.OPENAI_API_KEY
        self.encoder_model = settings.VECTOR_ENCODER_MODEL
        self.vector_dim = settings.VECTOR_DIM
        self.client_id = "mpa"
        self.class_prefix = "MPA"
        
        # ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬
        self.tool_registry = ToolRegistry()
        
        # MPA ì „ìš© ë„êµ¬ë“¤
        self.data_query_tool = None
        self.model_performance_tool = None
        self.prediction_tool = None
        self.anomaly_detection_tool = None
        self.compliance_tool = None
    
    def setup_tools(self) -> ToolRegistry:
        """MPA ì „ìš© ë„êµ¬ë“¤ì„ ì„¤ì •í•˜ê³  ë“±ë¡"""
        # 1. Data Query Tool ì„¤ì •
        # 2. Model Performance Tool ì„¤ì •
        # 3. Prediction Tool ì„¤ì •
        # 4. Anomaly Detection Tool ì„¤ì •
        # 5. Compliance Tool ì„¤ì •
        
        return self.tool_registry
    
    def create_data_query_tool(self):
        """ë°ì´í„° ì¡°íšŒ ë„êµ¬ ìƒì„±"""
        # ì œì¡° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        # SQL ì¿¼ë¦¬ ì‹¤í–‰
        # ê²°ê³¼ ì „ì²˜ë¦¬
    
    def create_model_performance_tool(self):
        """ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ë„êµ¬ ìƒì„±"""
        # ëª¨ë¸ ë¡œë“œ
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        # ê²°ê³¼ ë¹„êµ
    
    def create_prediction_tool(self):
        """ì˜ˆì¸¡ ë„êµ¬ ìƒì„±"""
        # ëª¨ë¸ ì„ íƒ
        # ì˜ˆì¸¡ ì‹¤í–‰
        # ê²°ê³¼ ê²€ì¦
    
    def create_anomaly_detection_tool(self):
        """ì´ìƒ íƒì§€ ë„êµ¬ ìƒì„±"""
        # ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜
        # ì„ê³„ê°’ ì„¤ì •
        # ê²°ê³¼ í•„í„°ë§
    
    def create_compliance_tool(self):
        """Compliance ê²€ì¦ ë„êµ¬ ìƒì„±"""
        # ê·œì • ê¸°ì¤€ ë¡œë“œ
        # ë°ì´í„° ê²€ì¦
        # ë³´ê³ ì„œ ìƒì„±
```

### 6. ì›Œí¬í”Œë¡œìš° ì •ì˜ (ìˆ˜ë„ ì½”ë“œ)

```python
def define_mpa_workflows(workflow_manager: WorkflowManager):
    """MPA Agent ì›Œí¬í”Œë¡œìš° ì •ì˜"""
    
    # 1. ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°
    data_analysis_steps = [
        {
            "name": "query_manufacturing_data",
            "type": "tool_call",
            "tool_name": "data_query_tool",
            "parameters": {
                "time_range": "{{time_range}}",
                "equipment_ids": "{{equipment_ids}}"
            }
        },
        {
            "name": "preprocess_data",
            "type": "tool_call",
            "tool_name": "data_preprocessing_tool",
            "parameters": {
                "data": "{{query_manufacturing_data.output}}"
            }
        }
    ]
    
    # 2. ëª¨ë¸ í‰ê°€ ì›Œí¬í”Œë¡œìš°
    model_evaluation_steps = [
        {
            "name": "load_models",
            "type": "tool_call",
            "tool_name": "model_loader_tool",
            "parameters": {
                "model_path": "{{model_storage_path}}"
            }
        },
        {
            "name": "evaluate_performance",
            "type": "tool_call",
            "tool_name": "model_performance_tool",
            "parameters": {
                "models": "{{load_models.output}}",
                "data": "{{preprocessed_data}}"
            }
        }
    ]
    
    # 3. ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš°
    prediction_steps = [
        {
            "name": "select_best_model",
            "type": "condition",
            "condition": "context['model_performance']['best_model']"
        },
        {
            "name": "execute_prediction",
            "type": "tool_call",
            "tool_name": "prediction_tool",
            "parameters": {
                "model": "{{select_best_model.output}}",
                "data": "{{preprocessed_data}}"
            }
        }
    ]
    
    # 4. ì´ìƒ íƒì§€ ì›Œí¬í”Œë¡œìš°
    anomaly_detection_steps = [
        {
            "name": "detect_anomalies",
            "type": "tool_call",
            "tool_name": "anomaly_detection_tool",
            "parameters": {
                "predictions": "{{execute_prediction.output}}",
                "historical_data": "{{preprocessed_data}}"
            }
        }
    ]
    
    # 5. Compliance ê²€ì¦ ì›Œí¬í”Œë¡œìš°
    compliance_verification_steps = [
        {
            "name": "verify_compliance",
            "type": "tool_call",
            "tool_name": "compliance_tool",
            "parameters": {
                "anomalies": "{{detect_anomalies.output}}",
                "predictions": "{{execute_prediction.output}}"
            }
        }
    ]
    
    # ì›Œí¬í”Œë¡œìš° ë“±ë¡
    workflow_manager.define_workflow("data_analysis", data_analysis_steps)
    workflow_manager.define_workflow("model_evaluation", model_evaluation_steps)
    workflow_manager.define_workflow("prediction", prediction_steps)
    workflow_manager.define_workflow("anomaly_detection", anomaly_detection_steps)
    workflow_manager.define_workflow("compliance_verification", compliance_verification_steps)
```

### 7. ë©”ì¸ ì‹¤í–‰ íŒŒì¼ (ìˆ˜ë„ ì½”ë“œ)

```python
# main.py
from fastapi import FastAPI
from src.agent.mpa_agent import ManufacturingPerformanceAgent

app = FastAPI(title="MPA Agent", version="1.0.0")

# ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
mpa_agent = ManufacturingPerformanceAgent()

@app.post("/api/analyze_performance")
async def analyze_manufacturing_performance(request: dict):
    """ì œì¡° ì„±ëŠ¥ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # 1. ìš”ì²­ íŒŒë¼ë¯¸í„° ê²€ì¦
        time_range = request.get("time_range")
        equipment_ids = request.get("equipment_ids")
        
        # 2. ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
        result = mpa_agent.analyze_manufacturing_performance(
            time_range=time_range,
            equipment_ids=equipment_ids
        )
        
        return {
            "success": True,
            "data": result
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/execute_workflow/{workflow_name}")
async def execute_workflow(workflow_name: str, context: dict):
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ API ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = mpa_agent.workflow_manager.execute_workflow(
            workflow_name, context
        )
        
        return {
            "success": True,
            "result": result
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8200)
```

### 8. ë°°í¬ ë° ì‹¤í–‰

```bash
# 1. ì—ì´ì „íŠ¸ ë¹Œë“œ
cd mpa-agent
docker build -t mpa-agent:latest .

# 2. ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# 3. API í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:8200/api/analyze_performance" \
  -H "Content-Type: application/json" \
  -d '{
    "time_range": {
      "start": "2024-01-01T00:00:00Z",
      "end": "2024-01-31T23:59:59Z"
    },
    "equipment_ids": ["EQ001", "EQ002", "EQ003"]
  }'
```

ì´ì œ PRISM-Coreë¥¼ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“œëŠ” ì „ì²´ ê³¼ì •ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€ 